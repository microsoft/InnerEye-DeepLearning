<!doctype html>
<html class="no-js" lang="en">
  <head><meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width,initial-scale=1"/>
    <meta name="color-scheme" content="light dark"><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />
<link rel="index" title="Index" href="../genindex.html" /><link rel="search" title="Search" href="../search.html" /><link rel="next" title="Using the InnerEye code as a git submodule of your project" href="innereye_as_submodule.html" /><link rel="prev" title="Bring Your Own PyTorch Lightning Model" href="bring_your_own_model.html" />

    <meta name="generator" content="sphinx-5.0.2, furo 2022.06.21"/>
        <title>Working with FastMRI models - InnerEye-DeepLearning 1.0.0 documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/furo.css?digest=40978830699223671f4072448e654b5958f38b89" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/furo-extensions.css?digest=30d1aed668e5c3a91c3e3bf6a60b675221979f0e" />
    
    


<style>
  body {
    --color-code-background: #f8f8f8;
  --color-code-foreground: black;
  
  }
  @media not print {
    body[data-theme="dark"] {
      --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
    }
    @media (prefers-color-scheme: dark) {
      body:not([data-theme="light"]) {
        --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
      }
    }
  }
</style></head>
  <body>
    
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    

<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024">
      <path d="M408 442h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8zm-8 204c0 4.4 3.6 8 8 8h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56zm504-486H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 632H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM115.4 518.9L271.7 642c5.8 4.6 14.4.5 14.4-6.9V388.9c0-7.4-8.5-11.5-14.4-6.9L115.4 505.1a8.74 8.74 0 0 0 0 13.8z"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-half" viewBox="0 0 24 24">
    <title>Auto light/dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-shadow">
      <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
      <circle cx="12" cy="12" r="9" />
      <path d="M13 12h5" />
      <path d="M13 15h4" />
      <path d="M13 18h1" />
      <path d="M13 9h4" />
      <path d="M13 6h1" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc">
<label class="overlay sidebar-overlay" for="__navigation">
  <div class="visually-hidden">Hide navigation sidebar</div>
</label>
<label class="overlay toc-overlay" for="__toc">
  <div class="visually-hidden">Hide table of contents sidebar</div>
</label>



<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <div class="visually-hidden">Toggle site navigation sidebar</div>
        <i class="icon"><svg><use href="#svg-menu"></use></svg></i>
      </label>
    </div>
    <div class="header-center">
      <a href="../index.html"><div class="brand">InnerEye-DeepLearning 1.0.0 documentation</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle">
          <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
          <svg class="theme-icon-when-auto"><use href="#svg-sun-half"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon" for="__toc">
        <div class="visually-hidden">Toggle table of contents sidebar</div>
        <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><a class="sidebar-brand" href="../index.html">
  
  
  <span class="sidebar-brand-text">InnerEye-DeepLearning 1.0.0 documentation</span>
  
</a><form class="sidebar-search-container" method="get" action="../search.html" role="search">
  <input class="sidebar-search" placeholder=Search name="q" aria-label="Search">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-scroll"><div class="sidebar-tree">
  <ul>
<li class="toctree-l1"><a class="reference internal" href="innereye_deeplearning.html">InnerEye-DeepLearning</a></li>
<li class="toctree-l1"><a class="reference internal" href="WSL.html">How to use the Windows Subsystem for Linux (WSL2) for development</a></li>
<li class="toctree-l1"><a class="reference internal" href="environment.html">Set up InnerEye-DeepLearning</a></li>
<li class="toctree-l1"><a class="reference internal" href="setting_up_aml.html">How to setup Azure Machine Learning for InnerEye</a></li>
<li class="toctree-l1"><a class="reference internal" href="creating_dataset.html">Dataset Creation</a></li>
<li class="toctree-l1"><a class="reference internal" href="building_models.html">Building Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="sample_tasks.html">Sample Tasks</a></li>
<li class="toctree-l1"><a class="reference internal" href="debugging_and_monitoring.html">Debugging and Monitoring Jobs</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Further reading for contributors</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="pull_requests.html">Suggested Workflow for Pull Requests</a></li>
<li class="toctree-l1"><a class="reference internal" href="testing.html">Pytest and testing on CPU and GPU machines</a></li>
<li class="toctree-l1"><a class="reference internal" href="contributing.html">Contributing</a></li>
<li class="toctree-l1"><a class="reference internal" href="hello_world_model.html">Training a Hello World segmentation model</a></li>
<li class="toctree-l1"><a class="reference internal" href="deploy_on_aml.html">Model Deployment</a></li>
<li class="toctree-l1"><a class="reference internal" href="bring_your_own_model.html">Bring Your Own PyTorch Lightning Model</a></li>
<li class="toctree-l1 current current-page"><a class="current reference internal" href="#">Working with FastMRI models</a></li>
<li class="toctree-l1"><a class="reference internal" href="innereye_as_submodule.html">Using the InnerEye code as a git submodule of your project</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_diagnostics.html">Model Diagnostics</a></li>
<li class="toctree-l1"><a class="reference internal" href="move_model.html">Move a model to other workspace</a></li>
<li class="toctree-l1"><a class="reference internal" href="releases.html">Releases</a></li>
<li class="toctree-l1"><a class="reference internal" href="self_supervised_models.html">Training of self-supervised models</a></li>
<li class="toctree-l1"><a class="reference internal" href="CHANGELOG.html">Changelog</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API documentation (🚧 Work In Progress 🚧)</span></p>
<ul>
<li class="toctree-l1 has-children"><a class="reference internal" href="../rst/api/ML/index.html">Machine learning</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" role="switch" type="checkbox"/><label for="toctree-checkbox-1"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../rst/api/ML/configs.html">Segmentation Model Configuration</a></li>
<li class="toctree-l2"><a class="reference internal" href="../rst/api/ML/runner.html">Runner</a></li>
<li class="toctree-l2"><a class="reference internal" href="../rst/api/ML/augmentations.html">Data augmentation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../rst/api/ML/photometric_normalization.html">Photometric normalization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../rst/api/ML/pipelines.html">Pipelines</a></li>
</ul>
</li>
</ul>

</div>
</div>

      </div>
      
    </div>
  </aside>
  <div class="main">
    <div class="content">
      <div class="article-container">
        <a href="#" class="back-to-top muted-link">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
          </svg>
          <span>Back to top</span>
        </a>
        <div class="content-icon-container">
          <div class="theme-toggle-container theme-toggle-content">
            <button class="theme-toggle">
              <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
              <svg class="theme-icon-when-auto"><use href="#svg-sun-half"></use></svg>
              <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
              <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
            </button>
          </div>
          <label class="toc-overlay-icon toc-content-icon" for="__toc">
            <div class="visually-hidden">Toggle table of contents sidebar</div>
            <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
          </label>
        </div>
        <article role="main">
          <section id="working-with-fastmri-models">
<h1>Working with FastMRI models<a class="headerlink" href="#working-with-fastmri-models" title="Permalink to this heading"></a></h1>
<p>The InnerEye toolbox supports models built for the <a class="reference external" href="https://fastmri.org/">fastMRI challenge</a>. The challenge supports
research into novel methods for reconstructing magnetic resonance images from undersampled data, with the ultimate
goal of speeding up MR acquisition and reducing cost.</p>
<p>Building even the baseline models for this challenge is computationally demanding, and can run for several days on
a single GPU box. With the help of the InnerEye toolbox and distributed training in Azure Machine Learning, this time
can be reduced dramatically.</p>
<p>In order to work with the challenge data in Azure, you will need to</p>
<ul class="simple">
<li><p>Register for the challenge</p></li>
<li><p>Have the InnerEye toolbox set up with Azure as described <a class="reference internal" href="setting_up_aml.html"><span class="doc">here</span></a></p></li>
<li><p>Download and prepare the challenge data, or use the script that we provide here to bulk download directly from
AWS into Azure blob storage.</p></li>
</ul>
<section id="registering-for-the-challenge">
<h2>Registering for the challenge<a class="headerlink" href="#registering-for-the-challenge" title="Permalink to this heading"></a></h2>
<p>In order to download the dataset, you need to register <a class="reference external" href="https://fastmri.org/dataset/">here</a>.</p>
<p>You will shortly receive an email with links to the dataset. In that email, there are two sections containing
scripts to download the data, like this:</p>
<p>To download Knee MRI files, we recommend using curl with recovery mode turned on:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>curl -C <span class="s2">&quot;https://....amazonaws.com/knee_singlecoil_train.tar.gz?AWSAccessKeyId=...Expires=1610309839&quot;</span> --output knee_singlecoil_train.tar.gz<span class="s2">&quot;</span>
<span class="s2">...</span>
</pre></div>
</div>
<p>There are two sections of that kind, one for the knee data and one for the brain data. Copy and paste <em>all</em> the lines
with <code class="docutils literal notranslate"><span class="pre">curl</span></code> commands into a text file, for example called <code class="docutils literal notranslate"><span class="pre">curl.txt</span></code>. In total, there should be 10 lines with <code class="docutils literal notranslate"><span class="pre">curl</span></code>
commands for the knee data, and 7 for the brain data (including the SHA256 file).</p>
</section>
<section id="download-the-dataset-directly-to-blob-storage-via-azure-data-factory">
<h2>Download the dataset directly to blob storage via Azure Data Factory<a class="headerlink" href="#download-the-dataset-directly-to-blob-storage-via-azure-data-factory" title="Permalink to this heading"></a></h2>
<p>We are providing a script that will bulk download all files in the FastMRI dataset from AWS to Azure blob storage.
To start that script, you need</p>
<ul class="simple">
<li><p>The file that contains all the <code class="docutils literal notranslate"><span class="pre">curl</span></code> commands to download the data (see above). The downloading script will
extract all the AWS access tokens from the <code class="docutils literal notranslate"><span class="pre">curl</span></code> commands.</p></li>
<li><p>The connection string to the Azure storage account that stores your dataset.</p>
<ul>
<li><p>To get that, navigate to the <a class="reference external" href="https://portal.azure.com">Azure Portal</a>, and search for the storage account
that you created to hold your datasets (Step 4 in <a class="reference internal" href="setting_up_aml.html"><span class="doc">AzureML setup</span></a>).</p></li>
<li><p>On the left hand navigation, there is a section “Access Keys”, select that and copy out the connection string
(sanity check: it should look something like <code class="docutils literal notranslate"><span class="pre">DefaultEndpointsProtocol=....==;EndpointSuffix=core.windows.net</span></code>)</p></li>
</ul>
</li>
<li><p>The Azure location where the Data Factory should be created (for example “westeurope”). The Data Factory should
live in the same Azure location as your AzureML workspace and storage account. To check the location,
find the workspace in the <a class="reference external" href="https://portal.azure.com">Azure Portal</a>, the location is shown on the overview page.</p></li>
</ul>
<p>Then run the script to download the dataset as follows, providing the path the the file with the curl commands
and the connection string as commandline arguments, enclosed in quotes:
<code class="docutils literal notranslate"><span class="pre">python</span> <span class="pre">InnerEye/Scripts/prepare_fastmri.py</span> <span class="pre">--curl</span> <span class="pre">curl.txt</span> <span class="pre">--connection_string</span> <span class="pre">&quot;&lt;your_connection_string&gt;&quot;</span></code> –location westeurope</p>
<p>This script will</p>
<ul class="simple">
<li><p>Authenticate against Azure either using the Service Principal credentials that you set up in Step 3 of the
<a class="reference internal" href="setting_up_aml.html"><span class="doc">AzureML setup</span></a>, or your own credentials. To use the latter, you need to be logged in via the Azure
command line interface (CLI), available <a class="reference external" href="https://docs.microsoft.com/en-us/cli/azure/">here</a> for all platforms.</p></li>
<li><p>Create an Azure Data Factory in the same resource group as the AzureML workspace.</p></li>
<li><p>Create pipelines to download the datasets in compressed form to the <code class="docutils literal notranslate"><span class="pre">datasets</span></code> container in the storage account
you supplied, and uncompress them.</p></li>
<li><p>Run all the pipelines and delete the Data Factory.</p></li>
</ul>
<p>This whole process can take a few hours to complete. It will print progress information every 30 seconds to the console.
Alternatively, find the Data Factory “fastmri-copy-data” in your Azure portal, and click on the “Monitor” icon to
drill down into all running pipelines.</p>
<p>Once the script is complete, you will have the following datasets in Azure blob storage:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">knee_singlecoil</span></code>, <code class="docutils literal notranslate"><span class="pre">knee_multicoil</span></code>, and <code class="docutils literal notranslate"><span class="pre">brain_multicoil</span></code> with all files unpacked</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">knee_singlecoil_compressed</span></code>, <code class="docutils literal notranslate"><span class="pre">knee_multicoil_compressed</span></code>, and <code class="docutils literal notranslate"><span class="pre">brain_multicoil_compressed</span></code> with the <code class="docutils literal notranslate"><span class="pre">.tar</span></code> and
<code class="docutils literal notranslate"><span class="pre">.tar.gz</span></code> files as downloaded. NOTE: The raw challenge data files all have a <code class="docutils literal notranslate"><span class="pre">.tar.gz</span></code> extension, even though some
of them are plain (uncompressed) <code class="docutils literal notranslate"><span class="pre">.tar</span></code> files. The pipeline corrects these mistakes and puts the files into blob storage
with their corrected extension.</p></li>
<li><p>The DICOM files are stored in the folders <code class="docutils literal notranslate"><span class="pre">knee_DICOMs</span></code> and <code class="docutils literal notranslate"><span class="pre">brain_DICOMs</span></code> (uncompressed) and
<code class="docutils literal notranslate"><span class="pre">knee_DICOMs_compressed</span></code> and <code class="docutils literal notranslate"><span class="pre">brain_DICOMs_compressed</span></code> (as <code class="docutils literal notranslate"><span class="pre">.tar</span></code> files)</p></li>
</ul>
<section id="troubleshooting-the-data-downloading">
<h3>Troubleshooting the data downloading<a class="headerlink" href="#troubleshooting-the-data-downloading" title="Permalink to this heading"></a></h3>
<p>If you see a runtime error saying “The subscription is not registered to use namespace ‘Microsoft.DataFactory’”, then
follow the steps described <a class="reference external" href="https://stackoverflow.com/a/48419951/5979993">here</a>, to enable DataFactory for your
subscription.</p>
</section>
</section>
<section id="running-a-fastmri-model-with-innereye">
<h2>Running a FastMri model with InnerEye<a class="headerlink" href="#running-a-fastmri-model-with-innereye" title="Permalink to this heading"></a></h2>
<p>The Azure Data Factory that downloaded the data has put it into the storage account you supplied on the commandline.
If set up correctly, this is the Azure storage account that holds all datasets used in your AzureML workspace.
Hence, after the downloading completes, you are ready to use the InnerEye toolbox to submit an AzureML job that uses
the FastMRI data.</p>
<p>There are 2 example models already coded up in the InnerEye toolbox, defined in
<a class="reference external" href="https://github.com/microsoft/InnerEye-DeepLearning/tree/main/InnerEye/ML/configs/other/fastmri_varnet.py">fastmri_varnet.py</a>: <code class="docutils literal notranslate"><span class="pre">KneeMulticoil</span></code> and
<code class="docutils literal notranslate"><span class="pre">BrainMulticoil</span></code>. As with all InnerEye models, you can start a training run by specifying the name of the class
that defines the model, like this:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>python InnerEye/ML/runner.py --model KneeMulticoil --azureml --num_nodes<span class="o">=</span><span class="m">4</span>
</pre></div>
</div>
<p>This will start an AzureML job with 4 nodes training at the same time. Depending on how you set up your compute
cluster, this will use a different number of GPUs: For example, if your cluster uses ND24 virtual machines, where
each VM has 4 Tesla P40 cards, training will use a total of 16 GPUs.</p>
<p>As common with multiple nodes, training time will not scale linearly with increased number of nodes. The following
table gives a rough overview of time to train 1 epoch of the FastMri model in the InnerEye toolbox
on our cluster (<code class="docutils literal notranslate"><span class="pre">Standard_ND24s</span></code> nodes with 4 Tesla P40 cards):</p>
<p>| Step | 1 node (4 GPUs) | 2 nodes (8 GPUs) | 4 nodes (16 GPUs) | 8 nodes (32 GPUs) |
| — | — | — | — | — |
| Download training data (1.25 TB) | 22min | 22min | 22min | 22min |
| Train and validate 1 epoch | 4h 15min | 2h 13min | 1h 6min | 34min |
| Evaluate on test set | 30min | 30min | 30min | 30min |
| Total time for 1 epoch | 5h 5min | 3h 5min | 1h 58min | 1h 26min |
| Total time for 50 epochs | 9 days | 4.6 days | 2.3 days | 1.2 days|</p>
<p>Note that the download times depend on the type of Azure storage account that your workspace is using. We recommend
using Premium storage accounts for optimal performance.</p>
<p>You can avoid the time to download the dataset, by specifying that the data is always read on-the-fly from the network.
For that, just add the <code class="docutils literal notranslate"><span class="pre">--use_dataset_mount</span></code> flag to the commandline. This may impact training throughput if
the storage account cannot provide the data quick enough - however, we have not observed a drop in GPU utilization even
when training on 8 nodes in parallel. For more details around dataset mounting please refer to the next section.</p>
</section>
<section id="performance-considerations-for-brainmulticoil">
<h2>Performance considerations for BrainMulticoil<a class="headerlink" href="#performance-considerations-for-brainmulticoil" title="Permalink to this heading"></a></h2>
<p>Training a FastMri model on the <code class="docutils literal notranslate"><span class="pre">brain_multicoil</span></code> dataset is particularly challenging because the dataset is larger.
Downloading the dataset can - depending on the types of nodes - already make the nodes go out of disk space.</p>
<p>The InnerEye toolbox has a way of working around that problem, by reading the dataset on-the-fly from the network,
rather than downloading it at the start of the job. You can trigger this behaviour by supplying an additional
commandline argument <code class="docutils literal notranslate"><span class="pre">--use_dataset_mount</span></code>, for example:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>python InnerEye/ML/runner.py --model BrainMulticoil --azureml --num_nodes<span class="o">=</span><span class="m">4</span> --use_dataset_mount
</pre></div>
</div>
<p>With this flag, the InnerEye training script will start immediately, without downloading data beforehand.
However, the fastMRI data module generates a cache file before training, and to build that, it needs to traverse the
full dataset. This will lead to a long (1-2 hours) startup time before starting the first epoch, while it is
creating this cache file. This can be avoided by copying the cache file from a previous run into to the dataset folder.
More specifically, you need to follow these steps:</p>
<ul class="simple">
<li><p>Start a training job, training for only 1 epoch, like</p></li>
</ul>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>python InnerEye/ML/runner.py --model BrainMulticoil --azureml --use_dataset_mount --num_epochs<span class="o">=</span><span class="m">1</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Wait until the job starts has finished creating the cache file - the job will print out a message
“Saving dataset cache to dataset_cache.pkl”, visible in the log file <code class="docutils literal notranslate"><span class="pre">azureml-logs/70_driver_log.txt</span></code>, about 1-2 hours
after start. At that point, you can cancel the job.</p></li>
<li><p>In the “Outputs + logs” section of the AzureML job, you will now see a file <code class="docutils literal notranslate"><span class="pre">outputs/dataset_cache.pkl</span></code> that has
been produced by the job. Download that file.</p></li>
<li><p>Upload the file <code class="docutils literal notranslate"><span class="pre">dataset_cache.pkl</span></code> to the storage account that holds the fastMRI datasets, in the <code class="docutils literal notranslate"><span class="pre">brain_multicoil</span></code>
folder that was previously created by the Azure Data Factory. You can do that via the Azure Portal or Azure Storage
Explorer. Via the Azure Portal, you can search for the storage account that holds your data, then select
“Data storage: Containers” in the left hand navigation. You should see a folder named <code class="docutils literal notranslate"><span class="pre">datasets</span></code>, and inside of that
<code class="docutils literal notranslate"><span class="pre">brain_multicoil</span></code>. Once in that folder, press the “Upload” button at the top and select the <code class="docutils literal notranslate"><span class="pre">dataset_cache.pkl</span></code> file.</p></li>
<li><p>Start the training job again, this time you can start multi-node training right away, like this:</p></li>
</ul>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>python InnerEye/ML/runner.py --model BrainMulticoil --azureml --use_dataset_mount --num_nodes<span class="o">=</span><span class="m">8</span>. This new
</pre></div>
</div>
<p>This job should pick up the existing cache file, and output a message like “Copying a pre-computed dataset cache
file …”</p>
<p>The same trick can of course be applied to other models as well (<code class="docutils literal notranslate"><span class="pre">KneeMulticoil</span></code>).</p>
</section>
<section id="running-on-a-gpu-machine">
<h2>Running on a GPU machine<a class="headerlink" href="#running-on-a-gpu-machine" title="Permalink to this heading"></a></h2>
<p>You can of course run the InnerEye fastMRI models on a reasonably large machine with a GPU for development and
debugging purposes. Before running, we recommend to download the datasets using a tool
like <a class="reference external" href="http://aka.ms/azcopy">azcopy</a> into a folder, for example the <code class="docutils literal notranslate"><span class="pre">datasets</span></code> folder at the repository root.</p>
<p>To use <code class="docutils literal notranslate"><span class="pre">azcopy</span></code>, you will need the access key to the storage account that holds your data - it’s the same storage
account that was used when creating the Data Factory that downloaded the data.</p>
<ul class="simple">
<li><p>To get that, navigate to the <a class="reference external" href="https://portal.azure.com">Azure Portal</a>, and search for the storage account
that you created to hold your datasets (Step 4 in <a class="reference internal" href="setting_up_aml.html"><span class="doc">AzureML setup</span></a>).</p></li>
<li><p>On the left hand navigation, there is a section “Access Keys”. Select that and copy out one of the two keys (<em>not</em>
the connection strings). The key is a base64 encoded string, it should not contain any special characters apart from
<code class="docutils literal notranslate"><span class="pre">+</span></code>, <code class="docutils literal notranslate"><span class="pre">/</span></code>, <code class="docutils literal notranslate"><span class="pre">.</span></code> and <code class="docutils literal notranslate"><span class="pre">=</span></code></p></li>
</ul>
<p>Then run this script in the repository root folder:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>mkdir datasets
azcopy --source-key &lt;storage_account_key&gt; --source https://&lt;your_storage_acount&gt;.blob.core.windows.net/datasets/brain_multicoil --destination datasets/brain_multicoil --recursive
</pre></div>
</div>
<p>Replace <code class="docutils literal notranslate"><span class="pre">brain_multicoil</span></code> with any of the other datasets names if needed.</p>
<p>If you follow these suggested folder structures, there is no further change necessary to the models. You can then
run, for example, the <code class="docutils literal notranslate"><span class="pre">BrainMulticoil</span></code> model by dropping the <code class="docutils literal notranslate"><span class="pre">--azureml</span></code> flag like this:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>python InnerEye/ML/runner.py --model BrainMulticoil
</pre></div>
</div>
<p>The code will recognize that an Azure dataset named <code class="docutils literal notranslate"><span class="pre">brain_multicoil</span></code> is already present in the <code class="docutils literal notranslate"><span class="pre">datasets</span></code> folder,
and skip the download.</p>
<p>If you choose to download the dataset to a different folder, for example <code class="docutils literal notranslate"><span class="pre">/foo/brain_multicoil</span></code>, you will need to
make a small adjustment to the model in <a class="reference external" href="https://github.com/microsoft/InnerEye-DeepLearning/tree/main/InnerEye/ML/configs/other/fastmri_varnet.py">fastmri_varnet.py</a>,
and add the <code class="docutils literal notranslate"><span class="pre">local_dataset</span></code> argument like this:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">BrainMulticoil</span><span class="p">(</span><span class="n">FastMri</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">azure_dataset_id</span> <span class="o">=</span> <span class="s2">&quot;brain_multicoil&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">local_dataset</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="s2">&quot;/foo/brain_multicoil&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dataset_mountpoint</span> <span class="o">=</span> <span class="s2">&quot;/tmp/brain_multicoil&quot;</span>
</pre></div>
</div>
</section>
</section>

        </article>
      </div>
      <footer>
        
        <div class="related-pages">
          <a class="next-page" href="innereye_as_submodule.html">
              <div class="page-info">
                <div class="context">
                  <span>Next</span>
                </div>
                <div class="title">Using the InnerEye code as a git submodule of your project</div>
              </div>
              <svg><use href="#svg-arrow-right"></use></svg>
            </a>
          <a class="prev-page" href="bring_your_own_model.html">
              <svg><use href="#svg-arrow-right"></use></svg>
              <div class="page-info">
                <div class="context">
                  <span>Previous</span>
                </div>
                
                <div class="title">Bring Your Own PyTorch Lightning Model</div>
                
              </div>
            </a>
        </div>
        <div class="bottom-of-page">
          <div class="left-details">
            <div class="copyright">
                Copyright &#169; Microsoft Corporation
            </div>
            Made with <a href="https://www.sphinx-doc.org/">Sphinx</a> and <a class="muted-link" href="https://pradyunsg.me">@pradyunsg</a>'s
            
            <a href="https://github.com/pradyunsg/furo">Furo</a>
            
          </div>
          <div class="right-details">
            <div class="icons">
              
            </div>
          </div>
        </div>
        
      </footer>
    </div>
    <aside class="toc-drawer">
      
      
      <div class="toc-sticky toc-scroll">
        <div class="toc-title-container">
          <span class="toc-title">
            Contents
          </span>
        </div>
        <div class="toc-tree-container">
          <div class="toc-tree">
            <ul>
<li><a class="reference internal" href="#">Working with FastMRI models</a><ul>
<li><a class="reference internal" href="#registering-for-the-challenge">Registering for the challenge</a></li>
<li><a class="reference internal" href="#download-the-dataset-directly-to-blob-storage-via-azure-data-factory">Download the dataset directly to blob storage via Azure Data Factory</a><ul>
<li><a class="reference internal" href="#troubleshooting-the-data-downloading">Troubleshooting the data downloading</a></li>
</ul>
</li>
<li><a class="reference internal" href="#running-a-fastmri-model-with-innereye">Running a FastMri model with InnerEye</a></li>
<li><a class="reference internal" href="#performance-considerations-for-brainmulticoil">Performance considerations for BrainMulticoil</a></li>
<li><a class="reference internal" href="#running-on-a-gpu-machine">Running on a GPU machine</a></li>
</ul>
</li>
</ul>

          </div>
        </div>
      </div>
      
      
    </aside>
  </div>
</div><script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/scripts/furo.js"></script>
    </body>
</html>