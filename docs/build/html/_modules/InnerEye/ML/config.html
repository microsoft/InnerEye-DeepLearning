<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>InnerEye.ML.config &mdash; InnerEye-DeepLearning 1.0.0 documentation</title>
      <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
        <script src="../../../_static/jquery.js"></script>
        <script src="../../../_static/underscore.js"></script>
        <script src="../../../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../../index.html" class="icon icon-home"> InnerEye-DeepLearning
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../../../docs/innereye_deeplearning.html">InnerEye-DeepLearning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../docs/WSL.html">How to use the Windows Subsystem for Linux (WSL2) for development</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../docs/environment.html">Set up InnerEye-DeepLearning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../docs/setting_up_aml.html">How to setup Azure Machine Learning for InnerEye</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../docs/creating_dataset.html">Dataset Creation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../docs/building_models.html">Building Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../docs/sample_tasks.html">Sample Tasks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../docs/debugging_and_monitoring.html">Debugging and Monitoring Jobs</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Further reading for contributors</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../docs/pull_requests.html">Suggested Workflow for Pull Requests</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../docs/testing.html">Pytest and testing on CPU and GPU machines</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../docs/contributing.html">Contributing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../docs/hello_world_model.html">Training a Hello World segmentation model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../docs/deploy_on_aml.html">Model Deployment</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../docs/bring_your_own_model.html">Bring Your Own PyTorch Lightning Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../docs/fastmri.html">Working with FastMRI models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../docs/innereye_as_submodule.html">Using the InnerEye code as a git submodule of your project</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../docs/model_diagnostics.html">Model Diagnostics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../docs/move_model.html">Move a model to other workspace</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../docs/releases.html">Releases</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../docs/self_supervised_models.html">Training of self-supervised models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../docs/CHANGELOG.html">Changelog</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API documentation (ðŸš§ Work In Progress ðŸš§)</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../rst/api/ML/index.html">Machine learning</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">InnerEye-DeepLearning</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="../../index.html">Module code</a> &raquo;</li>
      <li>InnerEye.ML.config</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for InnerEye.ML.config</h1><div class="highlight"><pre>
<span></span><span class="c1">#  ------------------------------------------------------------------------------------------</span>
<span class="c1">#  Copyright (c) Microsoft Corporation. All rights reserved.</span>
<span class="c1">#  Licensed under the MIT License (MIT). See LICENSE in the repo root for license information.</span>
<span class="c1">#  ------------------------------------------------------------------------------------------</span>
<span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">annotations</span>

<span class="kn">import</span> <span class="nn">logging</span>
<span class="kn">from</span> <span class="nn">dataclasses</span> <span class="kn">import</span> <span class="n">dataclass</span>
<span class="kn">from</span> <span class="nn">enum</span> <span class="kn">import</span> <span class="n">Enum</span><span class="p">,</span> <span class="n">unique</span>
<span class="kn">from</span> <span class="nn">math</span> <span class="kn">import</span> <span class="n">isclose</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Any</span><span class="p">,</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">List</span><span class="p">,</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Sequence</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">,</span> <span class="n">Union</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">param</span>
<span class="kn">from</span> <span class="nn">azureml.core</span> <span class="kn">import</span> <span class="n">ScriptRunConfig</span>
<span class="kn">from</span> <span class="nn">azureml.train.hyperdrive</span> <span class="kn">import</span> <span class="n">HyperDriveConfig</span>
<span class="kn">from</span> <span class="nn">pandas</span> <span class="kn">import</span> <span class="n">DataFrame</span>

<span class="kn">from</span> <span class="nn">InnerEye.Common.common_util</span> <span class="kn">import</span> <span class="n">any_pairwise_larger</span><span class="p">,</span> <span class="n">any_smaller_or_equal_than</span><span class="p">,</span> <span class="n">check_is_any_of</span>
<span class="kn">from</span> <span class="nn">InnerEye.Common.generic_parsing</span> <span class="kn">import</span> <span class="n">IntTuple</span>
<span class="kn">from</span> <span class="nn">InnerEye.Common.type_annotations</span> <span class="kn">import</span> <span class="n">TupleFloat2</span><span class="p">,</span> <span class="n">TupleFloat3</span><span class="p">,</span> <span class="n">TupleInt3</span><span class="p">,</span> <span class="n">TupleStringOptionalFloat</span>
<span class="kn">from</span> <span class="nn">InnerEye.ML.common</span> <span class="kn">import</span> <span class="n">ModelExecutionMode</span>
<span class="kn">from</span> <span class="nn">InnerEye.ML.deep_learning_config</span> <span class="kn">import</span> <span class="n">ModelCategory</span>
<span class="kn">from</span> <span class="nn">InnerEye.ML.model_config_base</span> <span class="kn">import</span> <span class="n">ModelConfigBase</span><span class="p">,</span> <span class="n">ModelTransformsPerExecutionMode</span>
<span class="kn">from</span> <span class="nn">InnerEye.ML.utils.split_dataset</span> <span class="kn">import</span> <span class="n">DatasetSplits</span>

<span class="n">DATASET_ID_FILE</span> <span class="o">=</span> <span class="s2">&quot;dataset_id.txt&quot;</span>
<span class="n">GROUND_TRUTH_IDS_FILE</span> <span class="o">=</span> <span class="s2">&quot;ground_truth_ids.txt&quot;</span>
<span class="n">IMAGE_CHANNEL_IDS_FILE</span> <span class="o">=</span> <span class="s2">&quot;image_channel_ids.txt&quot;</span>
<span class="n">BACKGROUND_CLASS_NAME</span> <span class="o">=</span> <span class="s2">&quot;background&quot;</span>
<span class="n">DEFAULT_POSTERIOR_VALUE_RANGE</span> <span class="o">=</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">EXAMPLE_IMAGES_FOLDER</span> <span class="o">=</span> <span class="s2">&quot;example_images&quot;</span>
<span class="n">LARGEST_CC_TYPE</span> <span class="o">=</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Sequence</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">TupleStringOptionalFloat</span><span class="p">]]]</span>


<div class="viewcode-block" id="PaddingMode"><a class="viewcode-back" href="../../../rst/api/ML/configs.html#InnerEye.ML.config.PaddingMode">[docs]</a><span class="nd">@unique</span>
<span class="k">class</span> <span class="nc">PaddingMode</span><span class="p">(</span><span class="n">Enum</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Supported padding modes for numpy and torch image padding.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1">#: Zero padding scheme.</span>
    <span class="n">Zero</span> <span class="o">=</span> <span class="s1">&#39;constant&#39;</span>
    <span class="c1">#: Pads with the edge values of array.</span>
    <span class="n">Edge</span> <span class="o">=</span> <span class="s1">&#39;edge&#39;</span>
    <span class="c1">#: Pads with the linear ramp between end_value and the array edge value.</span>
    <span class="n">LinearRamp</span> <span class="o">=</span> <span class="s2">&quot;linear_ramp&quot;</span>
    <span class="c1">#: Pads with the maximum value of all or part of the vector along each axis.</span>
    <span class="n">Maximum</span> <span class="o">=</span> <span class="s2">&quot;maximum&quot;</span>
    <span class="c1">#: Pads with the mean value of all or part of the vector along each axis.</span>
    <span class="n">Mean</span> <span class="o">=</span> <span class="s2">&quot;mean&quot;</span>
    <span class="c1">#: Pads with the median value of all or part of the vector along each axis.</span>
    <span class="n">Median</span> <span class="o">=</span> <span class="s2">&quot;median&quot;</span>
    <span class="c1">#: Pads with the minimum value of all or part of the vector along each axis.</span>
    <span class="n">Minimum</span> <span class="o">=</span> <span class="s2">&quot;minimum&quot;</span>
    <span class="c1">#: Pads with the reflection of the vector mirrored on the first and last values of the vector along each axis.</span>
    <span class="n">Reflect</span> <span class="o">=</span> <span class="s2">&quot;reflect&quot;</span>
    <span class="c1">#: Pads with the reflection of the vector mirrored along the edge of the array.</span>
    <span class="n">Symmetric</span> <span class="o">=</span> <span class="s2">&quot;symmetric&quot;</span>
    <span class="c1">#: Pads with the wrap of the vector along the axis.</span>
    <span class="c1">#: The first values are used to pad the end and the end values are used to pad the beginning.</span>
    <span class="n">Wrap</span> <span class="o">=</span> <span class="s2">&quot;wrap&quot;</span>
    <span class="c1">#: No padding is performed</span>
    <span class="n">NoPadding</span> <span class="o">=</span> <span class="s2">&quot;no_padding&quot;</span></div>


<div class="viewcode-block" id="EnsembleAggregationType"><a class="viewcode-back" href="../../../rst/api/ML/configs.html#InnerEye.ML.config.EnsembleAggregationType">[docs]</a><span class="nd">@unique</span>
<span class="k">class</span> <span class="nc">EnsembleAggregationType</span><span class="p">(</span><span class="n">Enum</span><span class="p">):</span>
    <span class="n">Average</span> <span class="o">=</span> <span class="s1">&#39;Average&#39;</span></div>


<div class="viewcode-block" id="PhotometricNormalizationMethod"><a class="viewcode-back" href="../../../rst/api/ML/configs.html#InnerEye.ML.config.PhotometricNormalizationMethod">[docs]</a><span class="nd">@unique</span>
<span class="k">class</span> <span class="nc">PhotometricNormalizationMethod</span><span class="p">(</span><span class="n">Enum</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Contains the valid methods that can be used to perform photometric normalization of a medical image.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">Unchanged</span> <span class="o">=</span> <span class="s2">&quot;None&quot;</span>
    <span class="n">SimpleNorm</span> <span class="o">=</span> <span class="s2">&quot;Simple Norm&quot;</span>
    <span class="n">MriWindow</span> <span class="o">=</span> <span class="s2">&quot;MRI Window&quot;</span>
    <span class="n">CtWindow</span> <span class="o">=</span> <span class="s2">&quot;CT Window&quot;</span>
    <span class="n">TrimmedNorm</span> <span class="o">=</span> <span class="s2">&quot;Trimmed Norm&quot;</span></div>


<div class="viewcode-block" id="ModelArchitectureConfig"><a class="viewcode-back" href="../../../rst/api/ML/configs.html#InnerEye.ML.config.ModelArchitectureConfig">[docs]</a><span class="k">class</span> <span class="nc">ModelArchitectureConfig</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Supported model architecture types</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">Basic</span> <span class="o">=</span> <span class="s1">&#39;Basic&#39;</span>
    <span class="n">UNet3D</span> <span class="o">=</span> <span class="s1">&#39;UNet3D&#39;</span>
    <span class="n">UNet2D</span> <span class="o">=</span> <span class="s1">&#39;UNet2D&#39;</span></div>


<div class="viewcode-block" id="SegmentationLoss"><a class="viewcode-back" href="../../../rst/api/ML/configs.html#InnerEye.ML.config.SegmentationLoss">[docs]</a><span class="nd">@unique</span>
<span class="k">class</span> <span class="nc">SegmentationLoss</span><span class="p">(</span><span class="n">Enum</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    The types of training loss that are supported for segmentation models.</span>
<span class="sd">    Parameters that can be set in the segmentation configs related to loss functions:</span>

<span class="sd">    |  SoftDice: :attr:`SegmentationModelBase.loss_class_weight_power`</span>
<span class="sd">    |  CrossEntropy: :attr:`SegmentationModelBase.loss_class_weight_power`,</span>
<span class="sd">        :attr:`DeepLearningConfig.label_smoothing_eps`</span>
<span class="sd">    |  Focal: :attr:`SegmentationModelBase.loss_class_weight_power`,</span>
<span class="sd">        :attr:`DeepLearningConfig.label_smoothing_eps`,</span>
<span class="sd">        :attr:`SegmentationModelBase.focal_loss_gamma`</span>
<span class="sd">    |  Mixture: :attr:`SegmentationModelBase.mixture_loss_components`.</span>
<span class="sd">        See :class:`MixtureLossComponent` for component parameters.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">SoftDice</span> <span class="o">=</span> <span class="s2">&quot;SoftDice&quot;</span>
    <span class="n">CrossEntropy</span> <span class="o">=</span> <span class="s2">&quot;CrossEntropy&quot;</span>
    <span class="n">Focal</span> <span class="o">=</span> <span class="s2">&quot;Focal&quot;</span>
    <span class="n">Mixture</span> <span class="o">=</span> <span class="s2">&quot;Mixture&quot;</span></div>


<div class="viewcode-block" id="MixtureLossComponent"><a class="viewcode-back" href="../../../rst/api/ML/configs.html#InnerEye.ML.config.MixtureLossComponent">[docs]</a><span class="nd">@dataclass</span>
<span class="k">class</span> <span class="nc">MixtureLossComponent</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A member of the value of the mixture_loss_components parameter.</span>

<span class="sd">    Parameters for the loss function will be pulled from the model config,</span>
<span class="sd">        except :attr:`SegmentationModelBase.loss_class_weight_power` which is ignored.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">weight</span><span class="p">:</span> <span class="nb">float</span>
    <span class="n">loss_type</span><span class="p">:</span> <span class="n">SegmentationLoss</span>
    <span class="c1">#: For weighted loss, power to which to raise the weights per class.</span>
    <span class="n">class_weight_power</span><span class="p">:</span> <span class="nb">float</span></div>


<div class="viewcode-block" id="SliceExclusionRule"><a class="viewcode-back" href="../../../rst/api/ML/configs.html#InnerEye.ML.config.SliceExclusionRule">[docs]</a><span class="nd">@dataclass</span>
<span class="k">class</span> <span class="nc">SliceExclusionRule</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Rule mandating that voxels of higher_class must always be in strictly higher slices than those of lower_class</span>
<span class="sd">    (slices are along the z-axis). If this is not the case, then if higher_dominates is True, any lower_class voxels in</span>
<span class="sd">    a higher or equal slice to any higher_class voxels are converted to higher_class. If higher_dominates</span>
<span class="sd">    is False, any higher_class voxels in a lower or equal slice to any lower_class voxels are converted to lower_class.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">higher_class</span><span class="p">:</span> <span class="nb">str</span>
    <span class="n">lower_class</span><span class="p">:</span> <span class="nb">str</span>
    <span class="n">higher_dominates</span><span class="p">:</span> <span class="nb">bool</span>

<div class="viewcode-block" id="SliceExclusionRule.validate"><a class="viewcode-back" href="../../../rst/api/ML/configs.html#InnerEye.ML.config.SliceExclusionRule.validate">[docs]</a>    <span class="k">def</span> <span class="nf">validate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ground_truth_ids</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Check this rule is valid for the given set of ground_truth_ids.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">higher_class</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">ground_truth_ids</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;slice_exclusion_rules: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">higher_class</span><span class="si">}</span><span class="s2"> not in ground truth IDs&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">lower_class</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">ground_truth_ids</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;slice_exclusion_rules: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">lower_class</span><span class="si">}</span><span class="s2"> not in ground truth IDs&quot;</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="SummedProbabilityRule"><a class="viewcode-back" href="../../../rst/api/ML/configs.html#InnerEye.ML.config.SummedProbabilityRule">[docs]</a><span class="nd">@dataclass</span>
<span class="k">class</span> <span class="nc">SummedProbabilityRule</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    At the boundary between two classes, the predicted class probability for both classes may be low. To avoid these</span>
<span class="sd">    voxels being categorized as external voxels, the summed probability of first_class and second_class will be used</span>
<span class="sd">    to create the segmentation map. If the summed probability of first_class and second_class is greater than</span>
<span class="sd">    external_class, we will label the voxel with first_class or second_class (whichever has the higher probability)</span>
<span class="sd">    instead of external_class.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">first_class</span><span class="p">:</span> <span class="nb">str</span>
    <span class="n">second_class</span><span class="p">:</span> <span class="nb">str</span>
    <span class="n">external_class</span><span class="p">:</span> <span class="nb">str</span>

<div class="viewcode-block" id="SummedProbabilityRule.validate"><a class="viewcode-back" href="../../../rst/api/ML/configs.html#InnerEye.ML.config.SummedProbabilityRule.validate">[docs]</a>    <span class="k">def</span> <span class="nf">validate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ground_truth_ids</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Check this rule is valid for the given set of ground_truth_ids.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">first_class</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">ground_truth_ids</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;SummedProbabilityRule.validate: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">first_class</span><span class="si">}</span><span class="s2"> not in ground truth IDs&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">second_class</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">ground_truth_ids</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;SummedProbabilityRule.validate: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">second_class</span><span class="si">}</span><span class="s2"> not in ground truth IDs&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">external_class</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">ground_truth_ids</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;SummedProbabilityRule.validate: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">external_class</span><span class="si">}</span><span class="s2"> not in ground truth IDs&quot;</span><span class="p">)</span></div></div>


<span class="c1"># The amount by which all Basic architectures shrink the input image.</span>
<span class="n">basic_size_shrinkage</span> <span class="o">=</span> <span class="mi">28</span>


<div class="viewcode-block" id="get_center_size"><a class="viewcode-back" href="../../../rst/api/ML/configs.html#InnerEye.ML.config.get_center_size">[docs]</a><span class="k">def</span> <span class="nf">get_center_size</span><span class="p">(</span><span class="n">arch</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">crop_size</span><span class="p">:</span> <span class="n">TupleInt3</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TupleInt3</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Computes the size of the output tensor, if the model is fed with an input tensor of the given crop_size.</span>
<span class="sd">    This makes a lot of assumptions about the architectures that are hardcoded, this method should be used with care.</span>

<span class="sd">    :param arch: The model architecture that is used.</span>
<span class="sd">    :param crop_size: The size of the model&#39;s input tensor.</span>
<span class="sd">    :return: The size of the model&#39;s output tensor.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">arch</span> <span class="o">==</span> <span class="n">ModelArchitectureConfig</span><span class="o">.</span><span class="n">UNet3D</span> <span class="ow">or</span> <span class="n">arch</span> <span class="o">==</span> <span class="n">ModelArchitectureConfig</span><span class="o">.</span><span class="n">UNet2D</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">crop_size</span>

    <span class="k">if</span> <span class="n">arch</span> <span class="ow">in</span> <span class="p">[</span><span class="n">ModelArchitectureConfig</span><span class="o">.</span><span class="n">Basic</span><span class="p">]:</span>
        <span class="n">diff</span> <span class="o">=</span> <span class="n">basic_size_shrinkage</span>
        <span class="k">return</span> <span class="n">crop_size</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="n">diff</span><span class="p">,</span> <span class="n">crop_size</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">diff</span><span class="p">,</span> <span class="n">crop_size</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">-</span> <span class="n">diff</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s2">&quot;Unknown model architecture: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">arch</span><span class="p">))</span></div>


<div class="viewcode-block" id="equally_weighted_classes"><a class="viewcode-back" href="../../../rst/api/ML/configs.html#InnerEye.ML.config.equally_weighted_classes">[docs]</a><span class="k">def</span> <span class="nf">equally_weighted_classes</span><span class="p">(</span><span class="n">foreground_classes</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="n">background_weight</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Computes a list of weights for the background class and all foreground classes. If no background_weight</span>
<span class="sd">    is given, all foreground classes and the background class (class index 0) are given equal weight.</span>
<span class="sd">    If a background_weight is given explicitly, that weight is assigned to class index 0, and the rest of the weight</span>
<span class="sd">    is equally distributed across all foreground classes. All weights will sum to 1.0</span>

<span class="sd">    :param foreground_classes: The list of foreground classes that the model uses.</span>
<span class="sd">    :param background_weight: The weight that should be given to the background class (index 0). This can be None.</span>
<span class="sd">    :return: A list of length len(foreground_classes) + 1, with weights for all classes including the background class.</span>
<span class="sd">            The weights will sum to 1.0</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">num_foreground_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">foreground_classes</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">num_foreground_classes</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;No foreground class present.&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">background_weight</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">num_classes_with_background</span> <span class="o">=</span> <span class="n">num_foreground_classes</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="k">return</span> <span class="p">[</span><span class="mf">1.0</span> <span class="o">/</span> <span class="n">num_classes_with_background</span><span class="p">]</span> <span class="o">*</span> <span class="n">num_classes_with_background</span>
    <span class="k">if</span> <span class="n">background_weight</span> <span class="o">&lt;</span> <span class="mf">0.0</span> <span class="ow">or</span> <span class="n">background_weight</span> <span class="o">&gt;=</span> <span class="mf">1.0</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;background_weight must be in the interval [0, 1), but got: </span><span class="si">{</span><span class="n">background_weight</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">foreground_weight</span> <span class="o">=</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">-</span> <span class="n">background_weight</span><span class="p">)</span> <span class="o">/</span> <span class="n">num_foreground_classes</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">background_weight</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="n">foreground_weight</span><span class="p">]</span> <span class="o">*</span> <span class="n">num_foreground_classes</span></div>


<div class="viewcode-block" id="SegmentationModelBase"><a class="viewcode-back" href="../../../rst/api/ML/configs.html#InnerEye.ML.config.SegmentationModelBase">[docs]</a><span class="k">class</span> <span class="nc">SegmentationModelBase</span><span class="p">(</span><span class="n">ModelConfigBase</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A class that holds all settings that are specific to segmentation models.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1">#: The segmentation model architecture to use.</span>
    <span class="c1">#: Valid options are defined at :class:`ModelArchitectureConfig`: &#39;Basic (DeepMedic)&#39;, &#39;UNet3D&#39;, &#39;UNet2D&#39;</span>
    <span class="n">architecture</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">param</span><span class="o">.</span><span class="n">String</span><span class="p">(</span><span class="s2">&quot;Basic&quot;</span><span class="p">,</span> <span class="n">doc</span><span class="o">=</span><span class="s2">&quot;The model architecture (for example, UNet). Valid options are&quot;</span>
                                                  <span class="s2">&quot;UNet3D, UNet2D, Basic (DeepMedic)&quot;</span><span class="p">)</span>

    <span class="c1">#: The loss type to use during training.</span>
    <span class="c1">#: Valid options are defined at :class:`SegmentationLoss`: &quot;SoftDice&quot;, &quot;CrossEntropy&quot;, &quot;Focal&quot;, &quot;Mixture&quot;</span>
    <span class="n">loss_type</span><span class="p">:</span> <span class="n">SegmentationLoss</span> <span class="o">=</span> <span class="n">param</span><span class="o">.</span><span class="n">ClassSelector</span><span class="p">(</span><span class="n">default</span><span class="o">=</span><span class="n">SegmentationLoss</span><span class="o">.</span><span class="n">SoftDice</span><span class="p">,</span> <span class="n">class_</span><span class="o">=</span><span class="n">SegmentationLoss</span><span class="p">,</span>
                                                      <span class="n">instantiate</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">doc</span><span class="o">=</span><span class="s2">&quot;The loss_type to use&quot;</span><span class="p">)</span>

    <span class="c1">#: List of pairs of weights, loss types and class-weight-power values for use when loss_type is</span>
    <span class="c1">#: :attr:`SegmentationLoss.MixtureLoss`&quot;.</span>
    <span class="n">mixture_loss_components</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">MixtureLossComponent</span><span class="p">]]</span> <span class="o">=</span> <span class="n">param</span><span class="o">.</span><span class="n">List</span><span class="p">(</span>
        <span class="kc">None</span><span class="p">,</span> <span class="n">class_</span><span class="o">=</span><span class="n">MixtureLossComponent</span><span class="p">,</span> <span class="n">instantiate</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">doc</span><span class="o">=</span><span class="s2">&quot;List of pairs of weights, loss types and class-weight-power values for use when loss_type is MixtureLoss&quot;</span><span class="p">)</span>

    <span class="c1">#: For weighted loss, power to which to raise the weights per class. If this is None, loss is not weighted.</span>
    <span class="n">loss_class_weight_power</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="n">param</span><span class="o">.</span><span class="n">Number</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">allow_None</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                                            <span class="n">doc</span><span class="o">=</span><span class="s2">&quot;Power to which to raise class weights for loss &quot;</span>
                                                                <span class="s2">&quot;function; default value will depend on loss_type&quot;</span><span class="p">)</span>

    <span class="c1">#: Gamma value for focal loss: weight for each pixel is posterior likelihood to the power -focal_loss_gamma.</span>
    <span class="n">focal_loss_gamma</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="n">param</span><span class="o">.</span><span class="n">Number</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">doc</span><span class="o">=</span><span class="s2">&quot;Gamma value for focal loss: weight for each pixel is &quot;</span>
                                                    <span class="s2">&quot;posterior likelihood to the power -focal_loss_gamma.&quot;</span><span class="p">)</span>

    <span class="c1">#: The spacing X, Y, Z expected for all images in the dataset</span>
    <span class="n">dataset_expected_spacing_xyz</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">TupleFloat3</span><span class="p">]</span> <span class="o">=</span> <span class="n">param</span><span class="o">.</span><span class="n">NumericTuple</span><span class="p">(</span>
        <span class="kc">None</span><span class="p">,</span> <span class="n">length</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">allow_None</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">doc</span><span class="o">=</span><span class="s2">&quot;The spacing X, Y, Z expected for all images in the dataset&quot;</span><span class="p">)</span>

    <span class="c1">#: The number of feature channels at different stages of the model.</span>
    <span class="n">feature_channels</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="n">param</span><span class="o">.</span><span class="n">List</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">class_</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">bounds</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span> <span class="n">instantiate</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                                             <span class="n">doc</span><span class="o">=</span><span class="s2">&quot;The number of feature channels at different stages of the model.&quot;</span><span class="p">)</span>

    <span class="c1">#: The size of the convolution kernels.</span>
    <span class="n">kernel_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">param</span><span class="o">.</span><span class="n">Integer</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">bounds</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span> <span class="n">doc</span><span class="o">=</span><span class="s2">&quot;The size of the convolution kernels.&quot;</span><span class="p">)</span>

    <span class="c1">#: The number of image levels used in Unet (in encoding and decoding paths).</span>
    <span class="n">num_downsampling_paths</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">param</span><span class="o">.</span><span class="n">Integer</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="n">bounds</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span>
                                                <span class="n">instantiate</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                                                <span class="n">doc</span><span class="o">=</span><span class="s2">&quot;The number of levels used in a UNet architecture in encoding and &quot;</span>
                                                    <span class="s2">&quot;decoding paths.&quot;</span><span class="p">)</span>

    <span class="c1">#: The size of the random crops that will be drawn from the input images during training. This is also the</span>
    <span class="c1">#: input size of the model.</span>
    <span class="n">crop_size</span><span class="p">:</span> <span class="n">TupleInt3</span> <span class="o">=</span> <span class="n">IntTuple</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">length</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">doc</span><span class="o">=</span><span class="s2">&quot;The size of the random crops that will be &quot;</span>
                                                             <span class="s2">&quot;drawn from the input images. This is also the &quot;</span>
                                                             <span class="s2">&quot;input size of the model.&quot;</span><span class="p">)</span>

    <span class="c1">#: The names of the image input channels that the model consumes. These channels must be present in the</span>
    <span class="c1">#: dataset.csv file.</span>
    <span class="n">image_channels</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="n">param</span><span class="o">.</span><span class="n">List</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">class_</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">bounds</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span> <span class="n">instantiate</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                                           <span class="n">doc</span><span class="o">=</span><span class="s2">&quot;The names of the image input channels that the model consumes. &quot;</span>
                                               <span class="s2">&quot;These channels must be present in the dataset.csv file&quot;</span><span class="p">)</span>

    <span class="c1">#: The names of the ground truth channels that the model consumes. These channels must be present in the</span>
    <span class="c1">#: dataset.csv file</span>
    <span class="n">ground_truth_ids</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="n">param</span><span class="o">.</span><span class="n">List</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">class_</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">bounds</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span> <span class="n">instantiate</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                                             <span class="n">doc</span><span class="o">=</span><span class="s2">&quot;The names of the ground truth channels that the model consumes. &quot;</span>
                                                 <span class="s2">&quot;These channels must be present in the dataset.csv file&quot;</span><span class="p">)</span>

    <span class="c1">#: The name of the channel that contains the `inside/outside body` information (to mask out the background).</span>
    <span class="c1">#: This channel must be present in the dataset</span>
    <span class="n">mask_id</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="n">param</span><span class="o">.</span><span class="n">String</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">allow_None</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">doc</span><span class="o">=</span><span class="s2">&quot;The name of the channel that contains the &quot;</span>
                                                                     <span class="s2">&quot;`inside/outside body` information.&quot;</span>
                                                                     <span class="s2">&quot;This channel must be present in the dataset&quot;</span><span class="p">)</span>

    <span class="c1">#: The type of image normalization that should be applied. Must be of type</span>
    <span class="c1"># :attr:`PhotometricNormalizationMethod`: Unchanged, SimpleNorm, MriWindow , CtWindow, TrimmedNorm</span>
    <span class="n">norm_method</span><span class="p">:</span> <span class="n">PhotometricNormalizationMethod</span> <span class="o">=</span> \
        <span class="n">param</span><span class="o">.</span><span class="n">ClassSelector</span><span class="p">(</span><span class="n">default</span><span class="o">=</span><span class="n">PhotometricNormalizationMethod</span><span class="o">.</span><span class="n">CtWindow</span><span class="p">,</span>
                            <span class="n">class_</span><span class="o">=</span><span class="n">PhotometricNormalizationMethod</span><span class="p">,</span>
                            <span class="n">instantiate</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                            <span class="n">doc</span><span class="o">=</span><span class="s2">&quot;The type of image normalization that should be applied. Must be one of &quot;</span>
                                <span class="s2">&quot;Unchanged, SimpleNorm, MriWindow , CtWindow, TrimmedNorm&quot;</span><span class="p">)</span>

    <span class="c1">#: The Window setting for the :attr:`PhotometricNormalizationMethod.CtWindow` normalization.</span>
    <span class="n">window</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">param</span><span class="o">.</span><span class="n">Integer</span><span class="p">(</span><span class="mi">600</span><span class="p">,</span> <span class="n">bounds</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span> <span class="n">doc</span><span class="o">=</span><span class="s2">&quot;The Window setting for the &#39;CtWindow&#39; normalization.&quot;</span><span class="p">)</span>

    <span class="c1">#: The level setting for the :attr:`PhotometricNormalizationMethod.CtWindow` normalization.</span>
    <span class="n">level</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">param</span><span class="o">.</span><span class="n">Integer</span><span class="p">(</span><span class="mi">50</span><span class="p">,</span> <span class="n">doc</span><span class="o">=</span><span class="s2">&quot;The level setting for the &#39;CtWindow&#39; normalization.&quot;</span><span class="p">)</span>

    <span class="c1">#: The value range that image normalization should produce. This is the input range to the network.</span>
    <span class="n">output_range</span><span class="p">:</span> <span class="n">TupleFloat2</span> <span class="o">=</span> <span class="n">param</span><span class="o">.</span><span class="n">NumericTuple</span><span class="p">((</span><span class="o">-</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">),</span> <span class="n">length</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                                                   <span class="n">doc</span><span class="o">=</span><span class="s2">&quot;The value range that image normalization should produce. &quot;</span>
                                                       <span class="s2">&quot;This is the input range to the network.&quot;</span><span class="p">)</span>

    <span class="c1">#: If true, create additional plots during image normalization.</span>
    <span class="n">debug_mode</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="n">param</span><span class="o">.</span><span class="n">Boolean</span><span class="p">(</span><span class="kc">False</span><span class="p">,</span> <span class="n">doc</span><span class="o">=</span><span class="s2">&quot;If true, create additional plots during image normalization.&quot;</span><span class="p">)</span>

    <span class="c1">#: Tail parameter allows window range to be extended to right, used in</span>
    <span class="c1">#: :attr:`PhotometricNormalizationMethod.MriWindow`. The value must be a list with one entry per input channel</span>
    <span class="c1">#: if the model has multiple input channels</span>
    <span class="n">tail</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="n">param</span><span class="o">.</span><span class="n">List</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">class_</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span>
                                   <span class="n">doc</span><span class="o">=</span><span class="s2">&quot;Tail parameter allows window range to be extended to right, Used in MriWindow.&quot;</span>
                                       <span class="s2">&quot; The value must be a list with one entry per input channel &quot;</span>
                                       <span class="s2">&quot;if the model has multiple input channels.&quot;</span><span class="p">)</span>

    <span class="c1">#: Sharpen parameter specifies number of standard deviations from mean to be included in window range.</span>
    <span class="c1">#: Used in :attr:`PhotometricNormalizationMethod.MriWindow`</span>
    <span class="n">sharpen</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="n">param</span><span class="o">.</span><span class="n">Number</span><span class="p">(</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">doc</span><span class="o">=</span><span class="s2">&quot;Sharpen parameter specifies number of standard deviations &quot;</span>
                                           <span class="s2">&quot;from mean to be included in window range. Used in MriWindow&quot;</span><span class="p">)</span>

    <span class="c1">#: Percentile at which to trim input distribution prior to normalization. Used in</span>
    <span class="c1">#: :attr:`PhotometricNormalizationMethod.TrimmedNorm`</span>
    <span class="n">trim_percentiles</span><span class="p">:</span> <span class="n">TupleFloat2</span> <span class="o">=</span> <span class="n">param</span><span class="o">.</span><span class="n">NumericTuple</span><span class="p">((</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">99.0</span><span class="p">),</span> <span class="n">length</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                                                       <span class="n">doc</span><span class="o">=</span><span class="s2">&quot;Percentile at which to trim input distribution prior &quot;</span>
                                                           <span class="s2">&quot;to normalization. Used in TrimmedNorm&quot;</span><span class="p">)</span>

    <span class="c1">#: Padding mode to use for training and inference. See :attr:`PaddingMode` for valid options.</span>
    <span class="n">padding_mode</span><span class="p">:</span> <span class="n">PaddingMode</span> <span class="o">=</span> <span class="n">param</span><span class="o">.</span><span class="n">ClassSelector</span><span class="p">(</span><span class="n">default</span><span class="o">=</span><span class="n">PaddingMode</span><span class="o">.</span><span class="n">Edge</span><span class="p">,</span> <span class="n">class_</span><span class="o">=</span><span class="n">PaddingMode</span><span class="p">,</span>
                                                    <span class="n">instantiate</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                                                    <span class="n">doc</span><span class="o">=</span><span class="s2">&quot;Padding mode to use for training and inference&quot;</span><span class="p">)</span>

    <span class="c1">#: The batch size to use for inference forward pass.</span>
    <span class="n">inference_batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">param</span><span class="o">.</span><span class="n">Integer</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="n">bounds</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span>
                                              <span class="n">doc</span><span class="o">=</span><span class="s2">&quot;The batch size to use for inference forward pass&quot;</span><span class="p">)</span>

    <span class="c1">#: The crop size to use for model testing. If nothing is specified, crop_size parameter is used instead,</span>
    <span class="c1">#: i.e. training and testing crop size will be the same.</span>
    <span class="n">test_crop_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">TupleInt3</span><span class="p">]</span> <span class="o">=</span> <span class="n">IntTuple</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">length</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">allow_None</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                                   <span class="n">doc</span><span class="o">=</span><span class="s2">&quot;The crop size to use for model testing. &quot;</span>
                                                       <span class="s2">&quot;If nothing is specified, &quot;</span>
                                                       <span class="s2">&quot;crop_size parameter is used instead, &quot;</span>
                                                       <span class="s2">&quot;i.e. training and testing crop size &quot;</span>
                                                       <span class="s2">&quot;will be the same.&quot;</span><span class="p">)</span>

    <span class="c1">#: The per-class probabilities for picking a center point of a crop.</span>
    <span class="n">class_weights</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">float</span><span class="p">]]</span> <span class="o">=</span> <span class="n">param</span><span class="o">.</span><span class="n">List</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">class_</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span> <span class="n">bounds</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span> <span class="n">allow_None</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                                      <span class="n">instantiate</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                                                      <span class="n">doc</span><span class="o">=</span><span class="s2">&quot;The per-class probabilities for picking a center point of &quot;</span>
                                                          <span class="s2">&quot;a crop.&quot;</span><span class="p">)</span>

    <span class="c1">#: Layer name hierarchy (parent, child recursive) as by model definition. If None, no activation maps will be saved</span>
    <span class="n">activation_map_layers</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="n">param</span><span class="o">.</span><span class="n">List</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">class_</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">allow_None</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">bounds</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span>
                                                            <span class="n">instantiate</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                                                            <span class="n">doc</span><span class="o">=</span><span class="s2">&quot;Layer name hierarchy (parent, child &quot;</span>
                                                                <span class="s2">&quot;recursive) as by model definition. If None, &quot;</span>
                                                                <span class="s2">&quot;no activation maps will be saved&quot;</span><span class="p">)</span>

    <span class="c1">#: The aggregation method to use when testing ensemble models. See :attr: `EnsembleAggregationType` for options.</span>
    <span class="n">ensemble_aggregation_type</span><span class="p">:</span> <span class="n">EnsembleAggregationType</span> <span class="o">=</span> <span class="n">param</span><span class="o">.</span><span class="n">ClassSelector</span><span class="p">(</span><span class="n">default</span><span class="o">=</span><span class="n">EnsembleAggregationType</span><span class="o">.</span><span class="n">Average</span><span class="p">,</span>
                                                                             <span class="n">class_</span><span class="o">=</span><span class="n">EnsembleAggregationType</span><span class="p">,</span>
                                                                             <span class="n">instantiate</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                                                                             <span class="n">doc</span><span class="o">=</span><span class="s2">&quot;The aggregation method to use when&quot;</span>
                                                                                 <span class="s2">&quot;testing ensemble models.&quot;</span><span class="p">)</span>

    <span class="c1">#: The size of the smoothing kernel in mm to be used for smoothing posteriors before computing the final</span>
    <span class="c1">#: segmentations. No smoothing is performed if set to None.</span>
    <span class="n">posterior_smoothing_mm</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">TupleInt3</span><span class="p">]</span> <span class="o">=</span> <span class="n">param</span><span class="o">.</span><span class="n">NumericTuple</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">length</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">allow_None</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                                                     <span class="n">doc</span><span class="o">=</span><span class="s2">&quot;The size of the smoothing kernel in mm to be &quot;</span>
                                                                         <span class="s2">&quot;used for smoothing posteriors before &quot;</span>
                                                                         <span class="s2">&quot;computing the final segmentations. No &quot;</span>
                                                                         <span class="s2">&quot;smoothing is performed if set to None&quot;</span><span class="p">)</span>

    <span class="c1">#: If True save image and segmentations for one image in a batch for each training epoch</span>
    <span class="n">store_dataset_sample</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="n">param</span><span class="o">.</span><span class="n">Boolean</span><span class="p">(</span><span class="kc">False</span><span class="p">,</span> <span class="n">doc</span><span class="o">=</span><span class="s2">&quot;If True save image and segmentations for one image&quot;</span>
                                                          <span class="s2">&quot;in a batch for each training epoch&quot;</span><span class="p">)</span>

    <span class="c1">#: List of (name, container) pairs, where name is a descriptive name and container is a Azure ML storage account</span>
    <span class="c1">#: container name to be used for statistical comparisons</span>
    <span class="n">comparison_blob_storage_paths</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="n">param</span><span class="o">.</span><span class="n">List</span><span class="p">(</span>
        <span class="kc">None</span><span class="p">,</span> <span class="n">class_</span><span class="o">=</span><span class="nb">tuple</span><span class="p">,</span>
        <span class="n">allow_None</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">doc</span><span class="o">=</span><span class="s2">&quot;List of (name, container) pairs, where name is a descriptive name and container is a &quot;</span>
            <span class="s2">&quot;Azure ML storage account container name to be used for statistical comparisons&quot;</span><span class="p">)</span>

    <span class="c1">#: List of rules for structures that should be prevented from sharing the same slice.</span>
    <span class="c1">#: These are not applied if :attr:`disable_extra_postprocessing` is True.</span>
    <span class="c1">#: Parameter should be a list of :attr:`SliceExclusionRule` objects.</span>
    <span class="n">slice_exclusion_rules</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">SliceExclusionRule</span><span class="p">]</span> <span class="o">=</span> <span class="n">param</span><span class="o">.</span><span class="n">List</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="p">[],</span> <span class="n">class_</span><span class="o">=</span><span class="n">SliceExclusionRule</span><span class="p">,</span> <span class="n">allow_None</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">doc</span><span class="o">=</span><span class="s2">&quot;List of rules for structures that should be prevented from sharing the same slice; &quot;</span>
            <span class="s2">&quot;not applied if disable_extra_postprocessing is True.&quot;</span><span class="p">)</span>

    <span class="c1">#: List of rules for class pairs whose summed probability is used to create the segmentation map from predicted</span>
    <span class="c1">#: posterior probabilities.</span>
    <span class="c1">#: These are not applied if :attr:`disable_extra_postprocessing` is True.</span>
    <span class="c1">#: Parameter should be a list of :attr:`SummedProbabilityRule` objects.</span>
    <span class="n">summed_probability_rules</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">SummedProbabilityRule</span><span class="p">]</span> <span class="o">=</span> <span class="n">param</span><span class="o">.</span><span class="n">List</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="p">[],</span> <span class="n">class_</span><span class="o">=</span><span class="n">SummedProbabilityRule</span><span class="p">,</span> <span class="n">allow_None</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">doc</span><span class="o">=</span><span class="s2">&quot;List of rules for class pairs whose summed probability is used to create the segmentation map from &quot;</span>
            <span class="s2">&quot;predicted posterior probabilities; not applied if disable_extra_postprocessing is True.&quot;</span><span class="p">)</span>

    <span class="c1">#: Whether to ignore :attr:`slice_exclusion_rules` and :attr:`summed_probability_rules` even if defined</span>
    <span class="n">disable_extra_postprocessing</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="n">param</span><span class="o">.</span><span class="n">Boolean</span><span class="p">(</span>
        <span class="kc">False</span><span class="p">,</span> <span class="n">doc</span><span class="o">=</span><span class="s2">&quot;Whether to ignore slice_exclusion_rules and summed_probability_rules even if defined&quot;</span><span class="p">)</span>

    <span class="c1">#: User friendly display names to be used for each of the predicted GT classes. Default is ground_truth_ids if</span>
    <span class="c1">#: None provided</span>
    <span class="n">ground_truth_ids_display_names</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="n">param</span><span class="o">.</span><span class="n">List</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">class_</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">bounds</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span> <span class="n">instantiate</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                                                           <span class="n">allow_None</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                                           <span class="n">doc</span><span class="o">=</span><span class="s2">&quot;User friendly display names to be used for each of &quot;</span>
                                                               <span class="s2">&quot;the predicted GT classes. Default is ground_truth_ids &quot;</span>
                                                               <span class="s2">&quot;if None provided&quot;</span><span class="p">)</span>

    <span class="c1">#: Colours in (R, G, B) for the structures, same order as in ground_truth_ids_display_names</span>
    <span class="n">colours</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">TupleInt3</span><span class="p">]</span> <span class="o">=</span> <span class="n">param</span><span class="o">.</span><span class="n">List</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">class_</span><span class="o">=</span><span class="nb">tuple</span><span class="p">,</span> <span class="n">bounds</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span> <span class="n">instantiate</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                                          <span class="n">allow_None</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                          <span class="n">doc</span><span class="o">=</span><span class="s2">&quot;Colours in (R, G, B) for the structures, same order as in &quot;</span>
                                              <span class="s2">&quot;ground_truth_ids_display_names&quot;</span><span class="p">)</span>

    <span class="c1">#: List of bool specifiying if structures need filling holes. If True, the output of the model for that class</span>
    <span class="c1">#: will include postprocessing to fill holes, in the same order as in ground_truth_ids_display_names</span>
    <span class="n">fill_holes</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="n">param</span><span class="o">.</span><span class="n">List</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">class_</span><span class="o">=</span><span class="nb">bool</span><span class="p">,</span> <span class="n">bounds</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span> <span class="n">instantiate</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                                        <span class="n">allow_None</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                        <span class="n">doc</span><span class="o">=</span><span class="s2">&quot;List of bool specifiying if structures need filling holes. If True &quot;</span>
                                            <span class="s2">&quot;output of the model for that class includes postprocessing to fill holes, &quot;</span>
                                            <span class="s2">&quot;in the same order as in ground_truth_ids_display_names&quot;</span><span class="p">)</span>

    <span class="n">roi_interpreted_types</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="n">param</span><span class="o">.</span><span class="n">List</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">class_</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">bounds</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span> <span class="n">instantiate</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                                                  <span class="n">allow_None</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                                  <span class="n">doc</span><span class="o">=</span><span class="s2">&quot;List of str with the ROI interpreted Types. Possible values &quot;</span>
                                                      <span class="s2">&quot;(None, CTV, ORGAN, EXTERNAL)&quot;</span><span class="p">)</span>

    <span class="n">interpreter</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">param</span><span class="o">.</span><span class="n">String</span><span class="p">(</span><span class="s2">&quot;Default_Interpreter&quot;</span><span class="p">,</span> <span class="n">doc</span><span class="o">=</span><span class="s2">&quot;The interpreter that created the DICOM-RT file&quot;</span><span class="p">)</span>

    <span class="n">manufacturer</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">param</span><span class="o">.</span><span class="n">String</span><span class="p">(</span><span class="s2">&quot;Default_Manufacturer&quot;</span><span class="p">,</span> <span class="n">doc</span><span class="o">=</span><span class="s2">&quot;The manufacturer that created the DICOM-RT file&quot;</span><span class="p">)</span>

    <span class="n">_inference_stride_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">TupleInt3</span><span class="p">]</span> <span class="o">=</span> <span class="n">IntTuple</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">length</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">allow_None</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                                           <span class="n">doc</span><span class="o">=</span><span class="s2">&quot;The stride size in the inference pipeline. &quot;</span>
                                                               <span class="s2">&quot;At most, this should be the output_size to &quot;</span>
                                                               <span class="s2">&quot;avoid gaps in output posterior image. If it &quot;</span>
                                                               <span class="s2">&quot;is not specified, its value is set to &quot;</span>
                                                               <span class="s2">&quot;output size.&quot;</span><span class="p">)</span>
    <span class="n">_center_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">TupleInt3</span><span class="p">]</span> <span class="o">=</span> <span class="n">IntTuple</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">length</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">allow_None</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">_train_output_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">TupleInt3</span><span class="p">]</span> <span class="o">=</span> <span class="n">IntTuple</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">length</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">allow_None</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">_test_output_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">TupleInt3</span><span class="p">]</span> <span class="o">=</span> <span class="n">IntTuple</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">length</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">allow_None</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="c1">#: Dictionary of types to enforce for certain DataFrame columns, where key is column name and value is desired type.</span>
    <span class="n">col_type_converters</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="n">param</span><span class="o">.</span><span class="n">Dict</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span>
                                                               <span class="n">doc</span><span class="o">=</span><span class="s2">&quot;Dictionary of types to enforce for certain &quot;</span>
                                                                   <span class="s2">&quot;DataFrame columns, where key is column name &quot;</span>
                                                                   <span class="s2">&quot;and value is desired type.&quot;</span><span class="p">,</span>
                                                               <span class="n">allow_None</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">instantiate</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="n">_largest_connected_component_foreground_classes</span><span class="p">:</span> <span class="n">LARGEST_CC_TYPE</span> <span class="o">=</span> \
        <span class="n">param</span><span class="o">.</span><span class="n">List</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">class_</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">bounds</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span> <span class="n">instantiate</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">allow_None</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                   <span class="n">doc</span><span class="o">=</span><span class="s2">&quot;The names of the ground truth channels for which to select the largest connected component in &quot;</span>
                       <span class="s2">&quot;the model predictions as an inference post-processing step. Alternatively, a member of the &quot;</span>
                       <span class="s2">&quot;list can be a tuple (name, threshold), where name is a channel name and threshold is a value &quot;</span>
                       <span class="s2">&quot;between 0 and 0.5 such that disconnected components will be kept if their volume (relative &quot;</span>
                       <span class="s2">&quot;to the whole structure) exceeds that value.&quot;</span><span class="p">)</span>

    <span class="c1">#: If true, various overview plots with results are generated during model evaluation. Set to False if you see</span>
    <span class="c1">#: non-deterministic pull request build failures.</span>
    <span class="n">is_plotting_enabled</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="n">param</span><span class="o">.</span><span class="n">Boolean</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">doc</span><span class="o">=</span><span class="s2">&quot;If true, various overview plots with results are generated &quot;</span>
                                                        <span class="s2">&quot;during model evaluation. Set to False if you see &quot;</span>
                                                        <span class="s2">&quot;non-deterministic pull request build failures.&quot;</span><span class="p">)</span>

    <span class="n">show_patch_sampling</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">param</span><span class="o">.</span><span class="n">Integer</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">bounds</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span>
                                             <span class="n">doc</span><span class="o">=</span><span class="s2">&quot;Number of patients from the training set for which the effect of&quot;</span>
                                                 <span class="s2">&quot;patch sampling will be shown. Nifti images and thumbnails for each&quot;</span>
                                                 <span class="s2">&quot;of the first N subjects in the training set will be &quot;</span>
                                                 <span class="s2">&quot;written to the outputs folder.&quot;</span><span class="p">)</span>

    <span class="c1">#: If true an error is raised in InnerEye.ML.utils.io_util.load_labels_from_dataset_source if the labels are not</span>
    <span class="c1">#: mutually exclusive. Some loss functions (e.g. SoftDice) may produce results on overlapping labels, but others</span>
    <span class="c1"># (e.g.</span>
    <span class="c1">#: FocalLoss) will fail with a cryptic error message. Set to false if you are sure that you want to use labels that</span>
    <span class="c1">#: are not mutually exclusive.</span>
    <span class="n">check_exclusive</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="n">param</span><span class="o">.</span><span class="n">Boolean</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span>
                                          <span class="n">doc</span><span class="o">=</span><span class="s2">&quot;Raise an error if the segmentation labels are not mutually exclusive.&quot;</span><span class="p">)</span>

    <span class="n">allow_incomplete_labels</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="n">param</span><span class="o">.</span><span class="n">Boolean</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">doc</span><span class="o">=</span><span class="s2">&quot;If False, the default, then test patient data must include all of the ground truth labels. If true then &quot;</span>
            <span class="s2">&quot;some test patient data with missing ground truth data is allowed and will be reflected in the patient &quot;</span>
            <span class="s2">&quot;counts in the metrics and report.&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">center_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">TupleInt3</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                 <span class="n">inference_stride_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">TupleInt3</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                 <span class="n">min_l_rate</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
                 <span class="n">largest_connected_component_foreground_classes</span><span class="p">:</span> <span class="n">LARGEST_CC_TYPE</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                 <span class="o">**</span><span class="n">params</span><span class="p">:</span> <span class="n">Any</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">params</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">test_crop_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">test_crop_size</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">test_crop_size</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">crop_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">inference_stride_size</span> <span class="o">=</span> <span class="n">inference_stride_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">min_l_rate</span> <span class="o">=</span> <span class="n">min_l_rate</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">largest_connected_component_foreground_classes</span> <span class="o">=</span> <span class="n">largest_connected_component_foreground_classes</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_center_size</span> <span class="o">=</span> <span class="n">center_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_model_category</span> <span class="o">=</span> <span class="n">ModelCategory</span><span class="o">.</span><span class="n">Segmentation</span>

<div class="viewcode-block" id="SegmentationModelBase.validate"><a class="viewcode-back" href="../../../rst/api/ML/configs.html#InnerEye.ML.config.SegmentationModelBase.validate">[docs]</a>    <span class="k">def</span> <span class="nf">validate</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Validates the parameters stored in the present object.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">validate</span><span class="p">()</span>
        <span class="n">check_is_any_of</span><span class="p">(</span><span class="s2">&quot;Architecture&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">architecture</span><span class="p">,</span> <span class="nb">vars</span><span class="p">(</span><span class="n">ModelArchitectureConfig</span><span class="p">)</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>

        <span class="k">def</span> <span class="nf">len_or_zero</span><span class="p">(</span><span class="n">lst</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">Any</span><span class="p">]])</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
            <span class="k">return</span> <span class="mi">0</span> <span class="k">if</span> <span class="n">lst</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="nb">len</span><span class="p">(</span><span class="n">lst</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel_size</span> <span class="o">%</span> <span class="mi">2</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;The kernel size must be an odd number (kernel_size: </span><span class="si">{}</span><span class="s2">)&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">kernel_size</span><span class="p">))</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">architecture</span> <span class="o">!=</span> <span class="n">ModelArchitectureConfig</span><span class="o">.</span><span class="n">UNet3D</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">any_pairwise_larger</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">center_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">crop_size</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Each center_size should be less than or equal to the crop_size &quot;</span>
                                 <span class="s2">&quot;(center_size: </span><span class="si">{}</span><span class="s2">, crop_size: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">center_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">crop_size</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">crop_size</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">center_size</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;For UNet3D, the center size of each dimension should be equal to the crop size &quot;</span>
                                 <span class="s2">&quot;(center_size: </span><span class="si">{}</span><span class="s2">, crop_size: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">center_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">crop_size</span><span class="p">))</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">validate_inference_stride_size</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">inference_stride_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_output_size</span><span class="p">())</span>

        <span class="c1"># check to make sure there is no overlap between image and ground-truth channels</span>
        <span class="n">image_gt_intersect</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">intersect1d</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">image_channels</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">ground_truth_ids</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">image_gt_intersect</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Channels: </span><span class="si">{}</span><span class="s2"> were found in both image_channels, and ground_truth_ids&quot;</span>
                             <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">image_gt_intersect</span><span class="p">))</span>

        <span class="n">valid_norm_methods</span> <span class="o">=</span> <span class="p">[</span><span class="n">method</span><span class="o">.</span><span class="n">value</span> <span class="k">for</span> <span class="n">method</span> <span class="ow">in</span> <span class="n">PhotometricNormalizationMethod</span><span class="p">]</span>
        <span class="n">check_is_any_of</span><span class="p">(</span><span class="s2">&quot;norm_method&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm_method</span><span class="o">.</span><span class="n">value</span><span class="p">,</span> <span class="n">valid_norm_methods</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">trim_percentiles</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">2</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">trim_percentiles</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">trim_percentiles</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Thresholds should contain lower and upper percentile thresholds, but got: </span><span class="si">{}</span><span class="s2">&quot;</span>
                             <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">trim_percentiles</span><span class="p">))</span>

        <span class="k">if</span> <span class="n">len_or_zero</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">class_weights</span><span class="p">)</span> <span class="o">!=</span> <span class="p">(</span><span class="n">len_or_zero</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ground_truth_ids</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;class_weights needs to be equal to number of ground_truth_ids + 1&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">class_weights</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;class_weights must be set.&quot;</span><span class="p">)</span>
        <span class="n">SegmentationModelBase</span><span class="o">.</span><span class="n">validate_class_weights</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">class_weights</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">ground_truth_ids</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;ground_truth_ids is None&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ground_truth_ids_display_names</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ground_truth_ids</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;len(ground_truth_ids_display_names)!=len(ground_truth_ids)&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ground_truth_ids_display_names</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">colours</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;len(ground_truth_ids_display_names)!=len(colours)&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ground_truth_ids_display_names</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fill_holes</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;len(ground_truth_ids_display_names)!=len(fill_holes)&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">mean_teacher_alpha</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Mean teacher model is currently only supported for ScalarModels.&quot;</span>
                             <span class="s2">&quot;Please reset mean_teacher_alpha to None.&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">disable_extra_postprocessing</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">slice_exclusion_rules</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">rule</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">slice_exclusion_rules</span><span class="p">:</span>
                    <span class="n">rule</span><span class="o">.</span><span class="n">validate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ground_truth_ids</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">summed_probability_rules</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">rule</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">summed_probability_rules</span><span class="p">:</span>
                    <span class="n">rule</span><span class="o">.</span><span class="n">validate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ground_truth_ids</span><span class="p">)</span></div>

<div class="viewcode-block" id="SegmentationModelBase.validate_class_weights"><a class="viewcode-back" href="../../../rst/api/ML/configs.html#InnerEye.ML.config.SegmentationModelBase.validate_class_weights">[docs]</a>    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">validate_class_weights</span><span class="p">(</span><span class="n">class_weights</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">float</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Checks that the given list of class weights is valid: The weights must be positive and add up to 1.0.</span>
<span class="sd">        Raises a ValueError if that is not the case.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">isclose</span><span class="p">(</span><span class="nb">sum</span><span class="p">(</span><span class="n">class_weights</span><span class="p">),</span> <span class="mf">1.0</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;class_weights needs to add to 1 but it was: </span><span class="si">{</span><span class="nb">sum</span><span class="p">(</span><span class="n">class_weights</span><span class="p">)</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">class_weights</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;class_weights must have non-negative values only, found: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">class_weights</span><span class="p">))</span></div>

<div class="viewcode-block" id="SegmentationModelBase.validate_inference_stride_size"><a class="viewcode-back" href="../../../rst/api/ML/configs.html#InnerEye.ML.config.SegmentationModelBase.validate_inference_stride_size">[docs]</a>    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">validate_inference_stride_size</span><span class="p">(</span><span class="n">inference_stride_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">TupleInt3</span><span class="p">],</span>
                                       <span class="n">output_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">TupleInt3</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Checks that patch stride size is positive and smaller than output patch size to ensure that posterior</span>
<span class="sd">        predictions are obtained for all pixels</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">inference_stride_size</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">any_smaller_or_equal_than</span><span class="p">(</span><span class="n">inference_stride_size</span><span class="p">,</span> <span class="mi">0</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;inference_stride_size must be &gt; 0 in all dimensions, found: </span><span class="si">{}</span><span class="s2">&quot;</span>
                                 <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">inference_stride_size</span><span class="p">))</span>

            <span class="k">if</span> <span class="n">output_size</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">any_pairwise_larger</span><span class="p">(</span><span class="n">inference_stride_size</span><span class="p">,</span> <span class="n">output_size</span><span class="p">):</span>
                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;inference_stride_size must be &lt;= output_size in all dimensions&quot;</span>
                                     <span class="s2">&quot;Found: output_size=</span><span class="si">{}</span><span class="s2">, inference_stride_size=</span><span class="si">{}</span><span class="s2">&quot;</span>
                                     <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">output_size</span><span class="p">,</span> <span class="n">inference_stride_size</span><span class="p">))</span></div>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">number_of_image_channels</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Gets the number of image input channels that the model has (usually 1 CT channel, or multiple MR).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="mi">0</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">image_channels</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">image_channels</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">number_of_classes</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns the number of ground truth ids, including the background class.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="mi">1</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">ground_truth_ids</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ground_truth_ids</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">center_size</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TupleInt3</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Gets the size of the center crop that the model predicts.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_center_size</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">get_center_size</span><span class="p">(</span><span class="n">arch</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">architecture</span><span class="p">,</span> <span class="n">crop_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">crop_size</span><span class="p">)</span>
        <span class="ne">Warning</span><span class="p">(</span><span class="s2">&quot;&#39;center_size&#39; argument will soon be deprecated. Output shapes are inferred from models on the fly.&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_center_size</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">inference_stride_size</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="n">TupleInt3</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Gets the stride size that should be used when stitching patches at inference time.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_inference_stride_size</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_output_size</span><span class="p">(</span><span class="n">ModelExecutionMode</span><span class="o">.</span><span class="n">TEST</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_inference_stride_size</span>

    <span class="nd">@inference_stride_size</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">inference_stride_size</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">val</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">TupleInt3</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Sets the inference stride size with given value. This setter is used if output shape needs to be</span>
<span class="sd">        determined dynamically at run time</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_inference_stride_size</span> <span class="o">=</span> <span class="n">val</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">validate_inference_stride_size</span><span class="p">(</span><span class="n">inference_stride_size</span><span class="o">=</span><span class="n">val</span><span class="p">,</span>
                                            <span class="n">output_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">get_output_size</span><span class="p">(</span><span class="n">ModelExecutionMode</span><span class="o">.</span><span class="n">TEST</span><span class="p">))</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">example_images_folder</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Path</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Gets the full path in which the example images should be stored during training.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">outputs_folder</span> <span class="o">/</span> <span class="n">EXAMPLE_IMAGES_FOLDER</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">largest_connected_component_foreground_classes</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">LARGEST_CC_TYPE</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Gets the list of classes for which the largest connected components should be computed when predicting.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_largest_connected_component_foreground_classes</span>

    <span class="nd">@largest_connected_component_foreground_classes</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">largest_connected_component_foreground_classes</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">:</span> <span class="n">LARGEST_CC_TYPE</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Sets the list of classes for which the largest connected components should be computed when predicting.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">pairs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]]]]</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="n">value</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># Set all members to be tuples rather than just class names.</span>
            <span class="n">pairs</span> <span class="o">=</span> <span class="p">[</span><span class="n">val</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)</span> <span class="k">else</span> <span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span> <span class="k">for</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">value</span><span class="p">]</span>
            <span class="n">class_names</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">pair</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">pair</span> <span class="ow">in</span> <span class="n">pairs</span><span class="p">)</span>
            <span class="n">unknown_labels</span> <span class="o">=</span> <span class="n">class_names</span> <span class="o">-</span> <span class="nb">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ground_truth_ids</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">unknown_labels</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Found unknown labels </span><span class="si">{</span><span class="n">unknown_labels</span><span class="si">}</span><span class="s2"> in largest_connected_component_foreground_classes: &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;labels must exist in [</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">ground_truth_ids</span><span class="si">}</span><span class="s2">]&quot;</span><span class="p">)</span>
            <span class="n">bad_thresholds</span> <span class="o">=</span> <span class="p">[</span><span class="n">pair</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">pair</span> <span class="ow">in</span> <span class="n">pairs</span> <span class="k">if</span> <span class="p">(</span><span class="n">pair</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">)</span>
                              <span class="ow">and</span> <span class="p">(</span><span class="n">pair</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="mf">0.0</span> <span class="ow">or</span> <span class="n">pair</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">)]</span>  <span class="c1"># type: ignore</span>
            <span class="k">if</span> <span class="n">bad_thresholds</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Found bad threshold(s) </span><span class="si">{</span><span class="n">bad_thresholds</span><span class="si">}</span><span class="s2"> in largest_connected_component_foreground_classes: &quot;</span>
                    <span class="s2">&quot;thresholds must be positive and at most 0.5.&quot;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_largest_connected_component_foreground_classes</span> <span class="o">=</span> <span class="n">pairs</span>

<div class="viewcode-block" id="SegmentationModelBase.read_dataset_into_dataframe_and_pre_process"><a class="viewcode-back" href="../../../rst/api/ML/configs.html#InnerEye.ML.config.SegmentationModelBase.read_dataset_into_dataframe_and_pre_process">[docs]</a>    <span class="k">def</span> <span class="nf">read_dataset_into_dataframe_and_pre_process</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Loads a dataset from the dataset_csv file, and stores it in the present object.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">local_dataset</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span> <span class="s2">&quot;The dataset must be provided in self.local_dataset&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dataset_data_frame</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">local_dataset</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset_csv</span><span class="p">,</span>
                                              <span class="n">dtype</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span>
                                              <span class="n">converters</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">col_type_converters</span><span class="p">,</span>
                                              <span class="n">low_memory</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pre_process_dataset_dataframe</span><span class="p">()</span></div>

<div class="viewcode-block" id="SegmentationModelBase.get_parameter_search_hyperdrive_config"><a class="viewcode-back" href="../../../rst/api/ML/configs.html#InnerEye.ML.config.SegmentationModelBase.get_parameter_search_hyperdrive_config">[docs]</a>    <span class="k">def</span> <span class="nf">get_parameter_search_hyperdrive_config</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">run_config</span><span class="p">:</span> <span class="n">ScriptRunConfig</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">HyperDriveConfig</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Turns the given AzureML estimator (settings for running a job in AzureML) into a configuration object</span>
<span class="sd">        for doing hyperparameter searches.</span>

<span class="sd">        :param run_config: The settings for running a single AzureML job.</span>
<span class="sd">        :return: A HyperDriveConfig object for running multiple AzureML jobs.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">get_parameter_search_hyperdrive_config</span><span class="p">(</span><span class="n">run_config</span><span class="p">)</span></div>

<div class="viewcode-block" id="SegmentationModelBase.get_model_train_test_dataset_splits"><a class="viewcode-back" href="../../../rst/api/ML/configs.html#InnerEye.ML.config.SegmentationModelBase.get_model_train_test_dataset_splits">[docs]</a>    <span class="k">def</span> <span class="nf">get_model_train_test_dataset_splits</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dataset_df</span><span class="p">:</span> <span class="n">DataFrame</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">DatasetSplits</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes the training, validation and test splits for the model, from a dataframe that contains</span>
<span class="sd">        the full dataset.</span>

<span class="sd">        :param dataset_df: A dataframe that contains the full dataset that the model is using.</span>
<span class="sd">        :return: An instance of DatasetSplits with dataframes for training, validation and testing.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">get_model_train_test_dataset_splits</span><span class="p">(</span><span class="n">dataset_df</span><span class="p">)</span></div>

<div class="viewcode-block" id="SegmentationModelBase.get_output_size"><a class="viewcode-back" href="../../../rst/api/ML/configs.html#InnerEye.ML.config.SegmentationModelBase.get_output_size">[docs]</a>    <span class="k">def</span> <span class="nf">get_output_size</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">execution_mode</span><span class="p">:</span> <span class="n">ModelExecutionMode</span> <span class="o">=</span> <span class="n">ModelExecutionMode</span><span class="o">.</span><span class="n">TRAIN</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="n">TupleInt3</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns shape of model&#39;s output tensor for training, validation and testing inference modes</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">execution_mode</span> <span class="o">==</span> <span class="n">ModelExecutionMode</span><span class="o">.</span><span class="n">TRAIN</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span><span class="n">execution_mode</span> <span class="o">==</span> <span class="n">ModelExecutionMode</span><span class="o">.</span><span class="n">VAL</span><span class="p">):</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_train_output_size</span>
        <span class="k">elif</span> <span class="n">execution_mode</span> <span class="o">==</span> <span class="n">ModelExecutionMode</span><span class="o">.</span><span class="n">TEST</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_test_output_size</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Unknown execution mode &#39;</span><span class="si">{}</span><span class="s2">&#39; for function &#39;get_output_size&#39;&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">execution_mode</span><span class="p">))</span></div>

<div class="viewcode-block" id="SegmentationModelBase.set_derived_model_properties"><a class="viewcode-back" href="../../../rst/api/ML/configs.html#InnerEye.ML.config.SegmentationModelBase.set_derived_model_properties">[docs]</a>    <span class="k">def</span> <span class="nf">set_derived_model_properties</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">:</span> <span class="n">Any</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Updates the model config parameters that depend on how the segmentation model is structured.</span>
<span class="sd">        In particular, this computes the model&#39;s output size for the training and the inference crops.</span>
<span class="sd">        If the inference stride size is not set, then set it to be equal to the size of the inference output patches.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Computing model output size when fed with training crops of size </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">crop_size</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_train_output_size</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">get_output_shape</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">crop_size</span><span class="p">)</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Computing model output size when fed with inference crops of size </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">test_crop_size</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_test_output_size</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">get_output_shape</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">test_crop_size</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">inference_stride_size</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">inference_stride_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_test_output_size</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">any_pairwise_larger</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">inference_stride_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_test_output_size</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;The inference stride size </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">inference_stride_size</span><span class="si">}</span><span class="s2"> must be smaller than the &quot;</span>
                                 <span class="sa">f</span><span class="s2">&quot;model&#39;s output size </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_test_output_size</span><span class="si">}</span><span class="s2"> in each dimension.&quot;</span><span class="p">)</span></div>

<div class="viewcode-block" id="SegmentationModelBase.class_and_index_with_background"><a class="viewcode-back" href="../../../rst/api/ML/configs.html#InnerEye.ML.config.SegmentationModelBase.class_and_index_with_background">[docs]</a>    <span class="k">def</span> <span class="nf">class_and_index_with_background</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns a dict of class names to indices, including the background class.</span>
<span class="sd">        The class index assumes that background is class 0, foreground starts at 1.</span>
<span class="sd">        For example, if the ground_truth_ids are [&quot;foo&quot;, &quot;bar&quot;], the result</span>
<span class="sd">        is {&quot;background&quot;: 0, &quot;foo&quot;: 1, &quot;bar&quot;: 2}</span>

<span class="sd">        :return: A dict, one entry for each entry in ground_truth_ids + 1 for the background class.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">classes</span> <span class="o">=</span> <span class="p">{</span><span class="n">BACKGROUND_CLASS_NAME</span><span class="p">:</span> <span class="mi">0</span><span class="p">}</span>
        <span class="n">classes</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="n">x</span><span class="p">:</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ground_truth_ids</span><span class="p">)})</span>
        <span class="k">return</span> <span class="n">classes</span></div>

<div class="viewcode-block" id="SegmentationModelBase.create_and_set_torch_datasets"><a class="viewcode-back" href="../../../rst/api/ML/configs.html#InnerEye.ML.config.SegmentationModelBase.create_and_set_torch_datasets">[docs]</a>    <span class="k">def</span> <span class="nf">create_and_set_torch_datasets</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">for_training</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> <span class="n">for_inference</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Creates torch datasets for all model execution modes, and stores them in the object.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="kn">from</span> <span class="nn">InnerEye.ML.dataset.cropping_dataset</span> <span class="kn">import</span> <span class="n">CroppingDataset</span>
        <span class="kn">from</span> <span class="nn">InnerEye.ML.dataset.full_image_dataset</span> <span class="kn">import</span> <span class="n">FullImageDataset</span>

        <span class="n">dataset_splits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_dataset_splits</span><span class="p">()</span>
        <span class="n">crop_transforms</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_cropped_image_sample_transforms</span><span class="p">()</span>
        <span class="n">full_image_transforms</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_full_image_sample_transforms</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">for_training</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_datasets_for_training</span> <span class="o">=</span> <span class="p">{</span>
                <span class="n">ModelExecutionMode</span><span class="o">.</span><span class="n">TRAIN</span><span class="p">:</span> <span class="n">CroppingDataset</span><span class="p">(</span>
                    <span class="bp">self</span><span class="p">,</span>
                    <span class="n">dataset_splits</span><span class="o">.</span><span class="n">train</span><span class="p">,</span>
                    <span class="n">cropped_sample_transforms</span><span class="o">=</span><span class="n">crop_transforms</span><span class="o">.</span><span class="n">train</span><span class="p">,</span>  <span class="c1"># type: ignore</span>
                    <span class="n">full_image_sample_transforms</span><span class="o">=</span><span class="n">full_image_transforms</span><span class="o">.</span><span class="n">train</span><span class="p">),</span>  <span class="c1"># type: ignore</span>
                <span class="n">ModelExecutionMode</span><span class="o">.</span><span class="n">VAL</span><span class="p">:</span> <span class="n">CroppingDataset</span><span class="p">(</span>
                    <span class="bp">self</span><span class="p">,</span> <span class="n">dataset_splits</span><span class="o">.</span><span class="n">val</span><span class="p">,</span>
                    <span class="n">cropped_sample_transforms</span><span class="o">=</span><span class="n">crop_transforms</span><span class="o">.</span><span class="n">val</span><span class="p">,</span>  <span class="c1"># type: ignore</span>
                    <span class="n">full_image_sample_transforms</span><span class="o">=</span><span class="n">full_image_transforms</span><span class="o">.</span><span class="n">val</span><span class="p">),</span>  <span class="c1"># type: ignore</span>
            <span class="p">}</span>
        <span class="k">if</span> <span class="n">for_inference</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_datasets_for_inference</span> <span class="o">=</span> <span class="p">{</span>
                <span class="n">mode</span><span class="p">:</span> <span class="n">FullImageDataset</span><span class="p">(</span>
                    <span class="bp">self</span><span class="p">,</span>
                    <span class="n">dataset_splits</span><span class="p">[</span><span class="n">mode</span><span class="p">],</span>
                    <span class="n">full_image_sample_transforms</span><span class="o">=</span><span class="n">full_image_transforms</span><span class="o">.</span><span class="n">test</span><span class="p">)</span>  <span class="c1"># type: ignore</span>
                <span class="k">for</span> <span class="n">mode</span> <span class="ow">in</span> <span class="n">ModelExecutionMode</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset_splits</span><span class="p">[</span><span class="n">mode</span><span class="p">])</span> <span class="o">&gt;</span> <span class="mi">0</span>
            <span class="p">}</span></div>

<div class="viewcode-block" id="SegmentationModelBase.create_model"><a class="viewcode-back" href="../../../rst/api/ML/configs.html#InnerEye.ML.config.SegmentationModelBase.create_model">[docs]</a>    <span class="k">def</span> <span class="nf">create_model</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Creates a PyTorch model from the settings stored in the present object.</span>
<span class="sd">        :return: The network model as a torch.nn.Module object</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Use a local import here to avoid reliance on pytorch too early.</span>
        <span class="c1"># Return type should be BaseModel, but that would also introduce reliance on pytorch.</span>
        <span class="kn">from</span> <span class="nn">InnerEye.ML.utils.model_util</span> <span class="kn">import</span> <span class="n">build_net</span>
        <span class="k">return</span> <span class="n">build_net</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span></div>

<div class="viewcode-block" id="SegmentationModelBase.get_full_image_sample_transforms"><a class="viewcode-back" href="../../../rst/api/ML/configs.html#InnerEye.ML.config.SegmentationModelBase.get_full_image_sample_transforms">[docs]</a>    <span class="k">def</span> <span class="nf">get_full_image_sample_transforms</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ModelTransformsPerExecutionMode</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Get transforms to perform on full image samples for each model execution mode.</span>
<span class="sd">        By default only PhotometricNormalization is performed.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="kn">from</span> <span class="nn">InnerEye.ML.utils.transforms</span> <span class="kn">import</span> <span class="n">Compose3D</span>
        <span class="kn">from</span> <span class="nn">InnerEye.ML.photometric_normalization</span> <span class="kn">import</span> <span class="n">PhotometricNormalization</span>

        <span class="n">photometric_transformation</span> <span class="o">=</span> <span class="n">Compose3D</span><span class="p">(</span><span class="n">transforms</span><span class="o">=</span><span class="p">[</span><span class="n">PhotometricNormalization</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">use_gpu</span><span class="o">=</span><span class="kc">False</span><span class="p">)])</span>
        <span class="k">return</span> <span class="n">ModelTransformsPerExecutionMode</span><span class="p">(</span><span class="n">train</span><span class="o">=</span><span class="n">photometric_transformation</span><span class="p">,</span>
                                               <span class="n">val</span><span class="o">=</span><span class="n">photometric_transformation</span><span class="p">,</span>
                                               <span class="n">test</span><span class="o">=</span><span class="n">photometric_transformation</span><span class="p">)</span></div>

<div class="viewcode-block" id="SegmentationModelBase.get_cropped_image_sample_transforms"><a class="viewcode-back" href="../../../rst/api/ML/configs.html#InnerEye.ML.config.SegmentationModelBase.get_cropped_image_sample_transforms">[docs]</a>    <span class="k">def</span> <span class="nf">get_cropped_image_sample_transforms</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ModelTransformsPerExecutionMode</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Get transforms to perform on cropped samples for each model execution mode.</span>
<span class="sd">        By default no transformation is performed.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">ModelTransformsPerExecutionMode</span><span class="p">()</span></div></div>
</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright Microsoft Corporation.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>