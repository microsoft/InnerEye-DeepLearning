pr:
  branches:
    include:
    - '*'

name: PR-$(Date:yyyyMMdd)$(Rev:-r)
variables:
  model: 'BasicModel2Epochs'
  train: 'True'
  more_switches: '--log_level=DEBUG'
  run_recovery_id: ''
  tag: ''
  number_of_cross_validation_splits: 0
  cluster: 'training-nc12'
  # Disable a spurious warning
  # https://stackoverflow.com/questions/56859264/publishing-code-coverage-results-from-reportgenerator-not-working
  disable.coverage.autogenerate: 'true'

jobs:
  - job: Windows
    pool:
      vmImage: 'windows-2019'
    steps:
      - template: build.yaml

  - job: Linux
    pool:
      vmImage: 'ubuntu-18.04'
    steps:
      - template: build.yaml

  - job: TrainInAzureML
    variables:
      - name: tag
        value: 'TrainBasicModel'
    pool:
      vmImage: 'ubuntu-18.04'
    steps:
      - template: train_template.yml
        parameters:
          wait_for_completion: 'True'
          max_run_duration: '30m'
      - template: tests_after_training.yml
        parameters:
          pytest_mark: after_training_single_run
          test_run_title: tests_after_training_single_run

  - job: RunGpuTestsInAzureML
    variables:
      - name: tag
        value: 'RunGpuTests'
    pool:
      vmImage: 'ubuntu-18.04'
    steps:
      - template: train_template.yml
        parameters:
          wait_for_completion: 'True'
          pytest_mark: 'gpu or cpu_and_gpu or azureml'
          max_run_duration: '30m'
      - task: PublishTestResults@2
        inputs:
          testResultsFiles: '**/test-*.xml'
          testRunTitle: 'tests_on_AzureML'
        condition: succeededOrFailed()
        displayName: Publish test results

  # Now train a module, using the Github code as a submodule. Here, a simpler 1 channel model
  # is trained, because we use this build to also check the "submit_for_inference" code, that
  # presently only handles single channel models.
  - job: TrainInAzureMLViaSubmodule
    variables:
      - name: model
        value: 'BasicModel2Epochs1Channel'
      - name: tag
        value: 'Train1ChannelSubmodule'
    pool:
      vmImage: 'ubuntu-18.04'
    steps:
      - template: train_via_submodule.yml
        parameters:
          wait_for_completion: 'True'
          max_run_duration: '30m'

  # Train a 2-element ensemble model
  - job: TrainEnsemble
    variables:
      - name: model
        value: 'BasicModel2Epochs'
      - name: number_of_cross_validation_splits
        value: 2
      - name: tag
        value: 'TrainEnsemble'
    pool:
      vmImage: 'ubuntu-18.04'
    steps:
      - template: train_template.yml
        parameters:
          wait_for_completion: 'True'
          pytest_mark: ''
          max_run_duration: '1h'
      - template: tests_after_training.yml
        parameters:
          pytest_mark: after_training_ensemble_run
          test_run_title: tests_after_training_ensemble_run

      # Train a cross-validation classification model
      - job: TrainClassificationCV
        variables:
          - name: model
            value: 'GlaucomaPublic'
          - name: number_of_cross_validation_splits
            value: 2
          - name: tag
            value: 'TrainClassificationCV'
          - name: more_switches
              value: '--num_epochs=2'
        pool:
          vmImage: 'ubuntu-18.04'
        steps:
          - template: train_template.yml
            parameters:
              wait_for_completion: 'True'
              pytest_mark: ''
              max_run_duration: '1h'

  # Train a model on 2 nodes
  - job: Train2Nodes
    variables:
      - name: model
        value: 'BasicModel2EpochsMoreData'
      - name: tag
        value: 'Train2Nodes'
      - name: more_switches
        value: '--log_level=DEBUG --num_nodes=2'
    pool:
      vmImage: 'ubuntu-18.04'
    steps:
      - template: train_template.yml
        parameters:
          wait_for_completion: 'True'
          pytest_mark: ''
          max_run_duration: '1h'
      - template: tests_after_training.yml
        parameters:
          pytest_mark: after_training_2node
          test_run_title: tests_after_training_2node_run
